{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import os\n",
    "import couplets_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets/tensorflow_imp_char\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = './model_save/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = couplets_utils.load_datasets(max_vocabs_size=200, max_len=30)\n",
    "train_gen = dataset['train_gen']\n",
    "dev_gen = dataset['dev_gen']\n",
    "test_gen = dataset['test_gen']\n",
    "char2index = dataset['char2index']\n",
    "index2char = dataset['index2char']\n",
    "vocabs_size = dataset['vocabs_size']\n",
    "max_len = dataset['max_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (661869, 30)\n",
      "dev: (4000, 30)\n",
      "test: (4000, 30)\n"
     ]
    }
   ],
   "source": [
    "print('train:', train_gen.shape)\n",
    "print('dev:', dev_gen.shape)\n",
    "print('test:', test_gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    with tf.name_scope('input_placeholders'):\n",
    "        input = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input')\n",
    "        label = tf.placeholder(shape=(None, None), dtype=tf.int32, name='label')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "        \n",
    "    return input, label, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_cell(num_units, num_layers, keep_prob, batch_size):\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        def lstm():\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            dropout = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return dropout\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm() for _ in range(num_layers)])\n",
    "        init_zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(cell, embed_input, init_state):\n",
    "    with tf.name_scope('lstm_layer'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed_input, initial_state=init_state)\n",
    "        \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_units = 64\n",
    "lstm_layers = 1\n",
    "keep_prob = 1\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "epochs = 1\n",
    "grad_clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward(cell, input, init_state):\n",
    "    one_hot = tf.one_hot(input, vocabs_size, axis=-1)\n",
    "        \n",
    "    outputs, final_state = build_lstm_layer(cell, one_hot, init_state)\n",
    "    \n",
    "    logits = tf.layers.dense(outputs, vocabs_size, name='fc_layer')\n",
    "    outputs = tf.nn.softmax(logits)\n",
    "    \n",
    "    return outputs, logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(cost, lr, grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(lr)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(outputs, labels):\n",
    "    predicts = tf.cast(tf.argmax(outputs, axis=-1), tf.int32)\n",
    "    predicts = tf.reshape(predicts, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    is_rights = tf.equal(predicts, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_rights, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(gen, lr=lr, keep_prob=keep_prob, batch_size=batch_size, \n",
    "          epochs=epochs, max_step=100, print_step=50, resume=True):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl,\n",
    "                                                          init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    optimizer_op = build_optimizer(cost_op, lr, grad_clip)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, MODEL_SAVE_PATH)  \n",
    "    \n",
    "    costs = []\n",
    "    step = 0    \n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: keep_prob\n",
    "        }\n",
    "        \n",
    "        _, cost = sess.run([optimizer_op, cost_op],\n",
    "                                        feed_dict=feed_dict)\n",
    "        accuracy = accuracy_op.eval(feed_dict=feed_dict, session=sess)\n",
    "        \n",
    "        if step % print_step == 0:\n",
    "            print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step, cost, accuracy * 100))\n",
    "            costs.append(cost)\n",
    "            \n",
    "        if step == max_step:\n",
    "            step += 1\n",
    "            break\n",
    "        \n",
    "        step += 1\n",
    "    \n",
    "    if (step - 1) % print_step != 0:\n",
    "        print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step - 1, cost, accuracy * 100))\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './model_save/model.ckpt')\n",
    "        \n",
    "    sess.close()\n",
    "    \n",
    "    plt.plot(range(0, step, print_step), costs)\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n",
      "step:0--cost:3.5128--accuracy:%25.8073\n",
      "step:2--cost:3.3557--accuracy:%26.3021\n",
      "step:4--cost:3.3617--accuracy:%26.1719\n",
      "step:6--cost:3.3419--accuracy:%25.8333\n",
      "step:8--cost:3.3489--accuracy:%26.4583\n",
      "step:10--cost:3.2898--accuracy:%27.0052\n",
      "CPU times: user 5.07 s, sys: 531 ms, total: 5.6 s\n",
      "Wall time: 1.8 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEQUGCIiEpH/D4kzrG22wBjCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111beeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time train(test_gen, print_step=2, lr=0.01, keep_prob=1, epochs=1, max_step=10, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(gen, batch_size):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl, init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, MODEL_SAVE_PATH)  \n",
    "    \n",
    "    step = 0 \n",
    "    cost = 0\n",
    "    accuracy = 0\n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: 1\n",
    "        }\n",
    "        \n",
    "        step_cost, step_accuracy = sess.run([cost_op, accuracy_op], feed_dict=feed_dict)\n",
    "        cost += step_cost\n",
    "        accuracy += step_accuracy\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    cost = cost / step\n",
    "    accuracy = accuracy / step\n",
    "    \n",
    "    print('cost:{0:.4f} -- accuracy:%{1:.4f}'.format(cost, accuracy * 100))\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set:\n",
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n",
      "cost:3.2848 -- accuracy:%26.5055\n"
     ]
    }
   ],
   "source": [
    "print('dev set:')\n",
    "evaluate(dev_gen, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_char_from_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[1] = 0\n",
    "    p[0] = 0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(prime, top_n=5):\n",
    "    samples = list(prime)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  tf.cast(tf.shape(input_pl)[0], tf.float32), 1)\n",
    "    init_state_op = init_zero_state_op\n",
    "    outputs_op, _, final_state_op = build_forward(cell_op, input_pl, init_state_op)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, MODEL_SAVE_PATH) \n",
    "    \n",
    "    init_state = sess.run(init_state_op)\n",
    "    \n",
    "    for char in prime:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = char2index.get(char, 1)\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "    pick_char_index = pick_char_from_top_n(outputs, vocabs_size, top_n)\n",
    "    samples.append(index2char[pick_char_index])\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = pick_char_index\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "        pick_char_index = pick_char_from_top_n(outputs, vocabs_size, top_n)\n",
    "        pick_char = index2char[pick_char_index]\n",
    "        samples.append(pick_char)\n",
    "    \n",
    "        if pick_char == '。':\n",
    "            break\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'床前明月光。，春；；，风。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(prime='床前明月光', top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
