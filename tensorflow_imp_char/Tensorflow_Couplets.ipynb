{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "import helper\n",
    "from data_generator import CoupletsDataGenerator\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets/tensorflow_imp\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1000\n",
      "train_set shape: (766491, 52)\n",
      "dev_set shape: (4000, 40)\n",
      "test_set shape: (4000, 43)\n"
     ]
    }
   ],
   "source": [
    "vocab_size, index2word, word2index, train_set, dev_set, test_set = helper.process_dataset(vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq_len = train_set.shape[-1]\n",
    "dev_seq_len = dev_set.shape[-1]\n",
    "test_seq_len = test_set.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = CoupletsDataGenerator(train_set)\n",
    "dev_gen = CoupletsDataGenerator(dev_set)\n",
    "test_gen = CoupletsDataGenerator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    with tf.name_scope('input_placeholders'):\n",
    "        input = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input')\n",
    "        label = tf.placeholder(shape=(None, None), dtype=tf.int32, name='label')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "        \n",
    "    return input, label, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embeding_layer(input, vocab_size, embeding_dim):\n",
    "    with tf.name_scope('embeding_layer'):\n",
    "        embeding_matrix = tf.Variable(tf.random_uniform(shape=(vocab_size, embeding_dim),\n",
    "                                                        minval=-1, maxval=1, dtype=tf.float32),\n",
    "                                     name='embeding_matrix')\n",
    "        embeding = tf.nn.embedding_lookup(embeding_matrix, input, name='embed_lookup')\n",
    "        \n",
    "    return embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_cell(num_units, num_layers, keep_prob, batch_size):\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        def lstm():\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            dropout = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return dropout\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm() for _ in range(num_layers)])\n",
    "        init_zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(cell, embed_input, init_state):\n",
    "    with tf.name_scope('lstm_layer'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed_input, initial_state=init_state)\n",
    "        \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeding_dim = 200\n",
    "lstm_units = 64\n",
    "lstm_layers = 1\n",
    "keep_prob = 0.7\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "grad_clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward(cell, input, init_state):\n",
    "    embeding = build_embeding_layer(input, vocab_size, embeding_dim)\n",
    "    \n",
    "    outputs, final_state = build_lstm_layer(cell, embeding, init_state)\n",
    "    \n",
    "    logits = tf.layers.dense(outputs, vocab_size, name='fc_layer')\n",
    "    outputs = tf.nn.softmax(logits)\n",
    "    \n",
    "    return outputs, logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(cost, lr, grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(lr)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(outputs, labels):\n",
    "    predicts = tf.cast(tf.argmax(outputs, axis=-1), tf.int32)\n",
    "    predicts = tf.reshape(predicts, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    is_rights = tf.equal(predicts, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_rights, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(gen, lr=lr, keep_prob=keep_prob, batch_size=batch_size, \n",
    "          epochs=epochs, max_step=100, print_step=50, resume=True):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl,\n",
    "                                                          init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    optimizer_op = build_optimizer(cost_op, lr, grad_clip)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if resume and os.path.exists('./model_save'):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, './model_save/model.ckpt')  \n",
    "    \n",
    "    costs = []\n",
    "    step = 0    \n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: keep_prob\n",
    "        }\n",
    "        \n",
    "        _, cost = sess.run([optimizer_op, cost_op],\n",
    "                                        feed_dict=feed_dict)\n",
    "        accuracy = accuracy_op.eval(feed_dict=feed_dict, session=sess)\n",
    "        \n",
    "        if step % print_step == 0:\n",
    "            print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step, cost, accuracy * 10))\n",
    "            costs.append(cost)\n",
    "            \n",
    "        if step == max_step:\n",
    "            step += 1\n",
    "            break\n",
    "        \n",
    "        step += 1\n",
    "    \n",
    "    if (step - 1) % print_step != 0:\n",
    "        print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step - 1, cost, accuracy * 10))\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './model_save/model.ckpt')\n",
    "        \n",
    "    sess.close()\n",
    "    \n",
    "    plt.plot(range(0, step, print_step), costs)\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0--cost:6.9174--accuracy:%1.3336\n",
      "step:2--cost:5.9199--accuracy:%1.5280\n",
      "step:4--cost:4.7775--accuracy:%1.6733\n",
      "step:6--cost:3.6901--accuracy:%1.5298\n",
      "step:8--cost:3.0524--accuracy:%1.5952\n",
      "step:10--cost:3.0929--accuracy:%1.5498\n",
      "CPU times: user 12.5 s, sys: 1.53 s, total: 14.1 s\n",
      "Wall time: 3.16 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106ac9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time train(test_gen, print_step=2, lr=0.01, max_step=10, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(gen, batch_size, seq_len):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl, init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt')  \n",
    "    \n",
    "    step = 0 \n",
    "    cost = 0\n",
    "    accuracy = 0\n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: 1\n",
    "        }\n",
    "        \n",
    "        step_cost, step_accuracy = sess.run([cost_op, accuracy_op], feed_dict=feed_dict)\n",
    "        cost += step_cost\n",
    "        accuracy += step_accuracy\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    cost = cost / step\n",
    "    accuracy = accuracy / step\n",
    "    \n",
    "    print('cost:{0:.4f} -- accuracy:%{1:.4f}'.format(cost, accuracy * 100))\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set:\n",
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n",
      "cost:3.8221 -- accuracy:%15.9077\n"
     ]
    }
   ],
   "source": [
    "# print('train set:')\n",
    "# evaluate(train_gen, batch_size)\n",
    "print('dev set:')\n",
    "evaluate(dev_gen, 64, dev_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_word_from_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[1] = 0\n",
    "    p[0] = 0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(primes_list, top_n=5):\n",
    "    samples = primes_list.copy()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  tf.cast(tf.shape(input_pl)[0], tf.float32), 1)\n",
    "    init_state_op = init_zero_state_op\n",
    "    outputs_op, _, final_state_op = build_forward(cell_op, input_pl, init_state_op)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt') \n",
    "    \n",
    "    init_state = sess.run(init_state_op)\n",
    "    \n",
    "    for word in primes_list:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = word2index.get(word, 1)\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "    pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "    samples.append(index2word[pick_word_index])\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = pick_word_index\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "        pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "        pick_word = index2word[pick_word_index]\n",
    "        samples.append(pick_word)\n",
    "    \n",
    "        if pick_word == '。':\n",
    "            break\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'明天月。'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(primes_list=['明天'], top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(prime_sentence, top_n=5):\n",
    "    primes_list = list(jieba.cut(prime_sentence))\n",
    "    return sample(primes_list, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/n2/ndjtbc452y3c2qqh7g4wbly80000gn/T/jieba.cache\n",
      "Loading model cost 0.726 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'床前明月光，。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('床前明月光')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
