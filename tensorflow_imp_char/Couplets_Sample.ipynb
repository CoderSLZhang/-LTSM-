{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import os\n",
    "from datasets_creator import Datasets_creator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets/tensorflow_imp_char'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_units = 256\n",
    "lstm_layers = 2\n",
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './model_save/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creator = Datasets_creator('../datasets/all_couplets.txt', 20000, max_len)\n",
    "char2index, index2char = creator.get_chars_dict()\n",
    "vocabs_size = len(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    with tf.name_scope('input_placeholders'):\n",
    "        input = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input')\n",
    "        label = tf.placeholder(shape=(None, None), dtype=tf.int32, name='label')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "        \n",
    "    return input, label, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_cell(num_units, num_layers, keep_prob, batch_size):\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        def lstm():\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            dropout = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return dropout\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm() for _ in range(num_layers)])\n",
    "        init_zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(cell, embed_input, init_state):\n",
    "    with tf.name_scope('lstm_layer'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed_input, initial_state=init_state)\n",
    "        \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward(cell, input, init_state):\n",
    "    one_hot = tf.one_hot(input, vocabs_size, axis=-1)\n",
    "        \n",
    "    outputs, final_state = build_lstm_layer(cell, one_hot, init_state)\n",
    "    \n",
    "    logits = tf.layers.dense(outputs, vocabs_size, name='fc_layer')\n",
    "    outputs = tf.nn.softmax(logits)\n",
    "    \n",
    "    return outputs, logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_char_from_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[1] = 0\n",
    "    p[0] = 0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(prime, top_n=5):\n",
    "    samples = list(prime)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  tf.cast(tf.shape(input_pl)[0], tf.float32), 1)\n",
    "    init_state_op = init_zero_state_op\n",
    "    outputs_op, _, final_state_op = build_forward(cell_op, input_pl, init_state_op)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, MODEL_PATH) \n",
    "    \n",
    "    init_state = sess.run(init_state_op)\n",
    "    \n",
    "    for char in prime:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = char2index.get(char, 1)\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "    if len(prime) != 0:\n",
    "        pick_char_index = pick_char_from_top_n(outputs, vocabs_size, top_n)\n",
    "        samples.append(index2char[pick_char_index])\n",
    "    else:\n",
    "        pick_char_index = 0\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = pick_char_index\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "        pick_char_index = pick_char_from_top_n(outputs, vocabs_size, top_n)\n",
    "        pick_char = index2char[pick_char_index]\n",
    "        samples.append(pick_char)\n",
    "    \n",
    "        if pick_char == '。':\n",
    "            break\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'树木千秋，一壶天井千山画卷；春风一缕，千古春光万里天涯。'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(prime='', top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卓云科技，万家和光新大地；九具春，万众和谐展新章。\n",
      "卓云科技，心中华先；望天生画，风流天。\n",
      "卓云科技，一行龙城天宇缀；千年国粹，千秋古海有风云。\n",
      "卓云科技，五千河岳山山外；五星红彩，一轮万古万民情。\n",
      "卓云科技，万家春色，民家乐业；一山山地，海上海腾天。\n",
      "卓云科技，九重风流千载景色；一腔玉韵，多山春水一门春。\n",
      "卓云科技，人间千古；百年天井，万代心。\n",
      "卓云科技，千年不朽春风雨；百川新，一脉清光映水天。\n",
      "卓云科技，一轮光辉大地；一腔天地，万里春风圆。\n",
      "卓云科技，万代文明天地韵；四生大海，千年旗业有民心。\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "for _ in range(10):\n",
    "    print(sample(prime='卓云科技，', top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
