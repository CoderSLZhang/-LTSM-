{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zytec/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from couplets_utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = load_sample_datasets(vocabs_size=2000, max_len=30, batch_size=16, sample_size=1000, n_a=N_A)\n",
    "sample_gen = sample['sample_gen']\n",
    "index2word = sample['index2word']\n",
    "word2index = sample['word2index']\n",
    "vocabs_size = sample['vocabs_size']\n",
    "max_len = sample['max_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_gen length : 63\n"
     ]
    }
   ],
   "source": [
    "print('sample_gen length :', len(sample_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_model(n_x, n_a, Tx, keep_prob=0.5):    \n",
    "    input = Input(shape=(Tx, n_x), name='x0')\n",
    "    a_0_0 = Input(shape=(n_a,), name='a_0_0')\n",
    "    c_0_0 = Input(shape=(n_a,), name='c_0_0')\n",
    "    a_1_0 = Input(shape=(n_a,), name='a_1_0')\n",
    "    c_1_0 = Input(shape=(n_a,), name='c_1_0')\n",
    "        \n",
    "    a_0 = a_0_0\n",
    "    c_0 = c_0_0\n",
    "    a_1 = a_1_0\n",
    "    c_1 = c_1_0\n",
    "    \n",
    "    lstm_cell_0 = LSTM(units=n_a, return_state=True, name='lstm_0')\n",
    "    lstm_cell_1 = LSTM(units=n_a, return_state=True, name='lstm_1')\n",
    "    dense_layer_2 = Dense(units=n_x, activation='softmax', name='softmax_2')\n",
    "        \n",
    "    outputs = []\n",
    "        \n",
    "    for i in range(Tx):\n",
    "        x = Lambda(lambda j: j[:, i, :])(input)\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_0, x, c_0 = lstm_cell_0(x, initial_state=[a_0, c_0])\n",
    "        x = Dropout(rate=1-keep_prob)(x)\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_1, x, c_1 = lstm_cell_1(x, initial_state=[a_1, c_1])\n",
    "        x = Dropout(rate=1-keep_prob)(x)\n",
    "        x = dense_layer_2(x)\n",
    "        outputs.append(x)\n",
    "                            \n",
    "    model = Model(inputs=[input, a_0_0, c_0_0, a_1_0, c_1_0], outputs=outputs)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = create_train_model(vocabs_size, N_A, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "63/63 [==============================] - 65s 1s/step - loss: 157.4750 - softmax_2_loss: 2.2523 - softmax_2_acc: 0.0000e+00 - softmax_2_acc_1: 0.0000e+00 - softmax_2_acc_2: 0.0000e+00 - softmax_2_acc_3: 0.0000e+00 - softmax_2_acc_4: 9.9219e-04 - softmax_2_acc_5: 9.9219e-04 - softmax_2_acc_6: 0.0238 - softmax_2_acc_7: 0.0228 - softmax_2_acc_8: 0.0327 - softmax_2_acc_9: 0.0327 - softmax_2_acc_10: 0.0516 - softmax_2_acc_11: 0.0506 - softmax_2_acc_12: 0.1667 - softmax_2_acc_13: 0.1667 - softmax_2_acc_14: 0.1796 - softmax_2_acc_15: 0.1796 - softmax_2_acc_16: 0.6816 - softmax_2_acc_17: 0.6796 - softmax_2_acc_18: 0.6865 - softmax_2_acc_19: 0.6865 - softmax_2_acc_20: 0.7292 - softmax_2_acc_21: 0.7262 - softmax_2_acc_22: 0.7520 - softmax_2_acc_23: 0.7500 - softmax_2_acc_24: 0.7847 - softmax_2_acc_25: 0.7837 - softmax_2_acc_26: 0.9256 - softmax_2_acc_27: 0.9276 - softmax_2_acc_28: 0.9643 - softmax_2_acc_29: 0.9683 \n"
     ]
    }
   ],
   "source": [
    "result = train_model.fit_generator(sample_gen, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.save_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_infer_model(n_x, n_a, Tx):\n",
    "    input = Input(shape=(n_x,), name='x_0')\n",
    "    a_0_0 = Input(shape=(n_a,), name='a_0_0')\n",
    "    c_0_0 = Input(shape=(n_a,), name='c_0_0')\n",
    "    a_1_0 = Input(shape=(n_a,), name='a_1_0')\n",
    "    c_1_0 = Input(shape=(n_a,), name='c_1_0')\n",
    "    \n",
    "    x = input\n",
    "    a_0 = a_0_0\n",
    "    c_0 = c_0_0\n",
    "    a_1 = a_1_0\n",
    "    c_1 = c_1_0\n",
    "\n",
    "    lstm_cell_0 = LSTM(units=n_a, return_state=True, name='lstm_0')\n",
    "    lstm_cell_1 = LSTM(units=n_a, return_state=True, name='lstm_1')\n",
    "    dense_layer_2 = Dense(units=n_x, activation='softmax', name='softmax_2')\n",
    "    \n",
    "    def sample(x):\n",
    "        return  tf.one_hot(tf.multinomial(x, 1), n_x, axis=-1)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(Tx):              \n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_0, x, c_0 = lstm_cell_0(x, initial_state=[a_0, c_0])\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_1, x, c_1 = lstm_cell_1(x, initial_state=[a_1, c_1])\n",
    "        x = dense_layer_2(x)\n",
    "        x = Lambda(sample)(x)\n",
    "        x = Reshape((-1,))(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "    model = Model(inputs=[input, a_0_0, c_0_0, a_1_0, c_1_0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n",
      "(?, 2000)\n",
      "(?, ?)\n"
     ]
    }
   ],
   "source": [
    "infer_model = create_random_infer_model(vocabs_size, N_A, max_len)\n",
    "infer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model.load_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_couplets(num, infer_model):\n",
    "    x = np.zeros((num, vocabs_size))\n",
    "    a_0 = np.zeros((num, N_A))\n",
    "    c_0 = np.zeros((num, N_A))\n",
    "    a_1 = np.zeros((num, N_A))\n",
    "    c_1 = np.zeros((num, N_A))\n",
    "    \n",
    "    result = infer_model.predict([x, a_0, c_0, a_1, c_1])\n",
    "    result_text = convert_onehots_to_text(np.array(result), index2word)\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['章谓鲜溢敬肠板语酸暖白翠人锁那碑剪傲勿泰庆栏沁勾吃轻拥昼亭阁', '选材凭愚标材慨嫦欢服柏哲拜洪聊知愁复垒面醒圆瓯备赋新泻总贪妨', '狼立软温帅扬比并庙暗补助培效赏生认庶宛屋酿设侠蒙奔辱互凭龟航']\n"
     ]
    }
   ],
   "source": [
    "text = '天天向上'\n",
    "result_text = write_couplets(3, infer_model)\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
