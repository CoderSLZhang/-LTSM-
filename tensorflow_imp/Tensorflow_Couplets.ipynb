{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "import helper\n",
    "from data_generator import CoupletsDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets/tensorflow_imp\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1000\n",
      "train_set shape: (766491, 52)\n",
      "dev_set shape: (4000, 40)\n",
      "test_set shape: (4000, 43)\n"
     ]
    }
   ],
   "source": [
    "vocab_size, index2word, word2index, train_set, dev_set, test_set = helper.process_dataset(vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq_len = train_set.shape[-1]\n",
    "dev_seq_len = dev_set.shape[-1]\n",
    "test_seq_len = test_set.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = CoupletsDataGenerator(train_set)\n",
    "dev_gen = CoupletsDataGenerator(dev_set)\n",
    "test_gen = CoupletsDataGenerator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    with tf.name_scope('input_placeholders'):\n",
    "        input = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input')\n",
    "        label = tf.placeholder(shape=(None, None), dtype=tf.int32, name='label')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "        \n",
    "    return input, label, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embeding_layer(input, vocab_size, embeding_dim):\n",
    "    with tf.name_scope('embeding_layer'):\n",
    "        embeding_matrix = tf.Variable(tf.random_uniform(shape=(vocab_size, embeding_dim),\n",
    "                                                        minval=-1, maxval=1, dtype=tf.float32),\n",
    "                                     name='embeding_matrix')\n",
    "        embeding = tf.nn.embedding_lookup(embeding_matrix, input, name='embed_lookup')\n",
    "        \n",
    "    return embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_cell(num_units, num_layers, keep_prob, batch_size):\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        def lstm():\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            dropout = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return dropout\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm() for _ in range(num_layers)])\n",
    "        init_zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(cell, embed_input, init_state):\n",
    "    with tf.name_scope('lstm_layer'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed_input, initial_state=init_state)\n",
    "        \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeding_dim = 200\n",
    "lstm_units = 64\n",
    "lstm_layers = 1\n",
    "keep_prob = 0.7\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "grad_clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward(cell, input, init_state):\n",
    "    embeding = build_embeding_layer(input, vocab_size, embeding_dim)\n",
    "    \n",
    "    outputs, final_state = build_lstm_layer(cell, embeding, init_state)\n",
    "    \n",
    "    logits = tf.layers.dense(outputs, vocab_size, name='fc_layer')\n",
    "    outputs = tf.nn.softmax(logits)\n",
    "    \n",
    "    return outputs, logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(cost, lr, grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(lr)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(outputs, labels):\n",
    "    predicts = tf.cast(tf.argmax(outputs, axis=-1), tf.int32)\n",
    "    predicts = tf.reshape(predicts, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    is_rights = tf.equal(predicts, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_rights, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(gen, lr=lr, batch_size=batch_size, epochs=epochs, \n",
    "          keep_prob=keep_prob, print_step=50):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl,\n",
    "                                                          init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    optimizer_op = build_optimizer(cost_op, lr, grad_clip)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0    \n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: keep_prob\n",
    "        }\n",
    "        \n",
    "        _, cost = sess.run([optimizer_op, cost_op],\n",
    "                                        feed_dict=feed_dict)\n",
    "        accuracy = accuracy_op.eval(feed_dict=feed_dict, session=sess)\n",
    "        \n",
    "        if step % print_step == 0:\n",
    "            print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step, cost, accuracy * 10))\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './model_save/model.ckpt')\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0--cost:6.9060--accuracy:%0.1272\n",
      "step:1--cost:6.8377--accuracy:%0.8049\n",
      "step:2--cost:6.7521--accuracy:%1.3572\n",
      "step:3--cost:6.6859--accuracy:%1.1446\n",
      "step:4--cost:6.6215--accuracy:%1.2718\n",
      "step:5--cost:6.5445--accuracy:%1.2918\n",
      "step:6--cost:6.4565--accuracy:%1.2991\n",
      "step:7--cost:6.3921--accuracy:%1.2827\n",
      "step:8--cost:6.3234--accuracy:%1.3118\n",
      "step:9--cost:6.2309--accuracy:%1.3209\n",
      "step:10--cost:6.1350--accuracy:%1.4517\n",
      "step:11--cost:5.9773--accuracy:%1.6061\n",
      "step:12--cost:5.9791--accuracy:%1.3972\n",
      "step:13--cost:5.7891--accuracy:%1.6352\n",
      "step:14--cost:5.7583--accuracy:%1.4299\n",
      "step:15--cost:5.6220--accuracy:%1.5062\n",
      "step:16--cost:5.5019--accuracy:%1.4989\n",
      "step:17--cost:5.3787--accuracy:%1.5643\n",
      "step:18--cost:5.3590--accuracy:%1.5407\n",
      "step:19--cost:5.2283--accuracy:%1.5461\n",
      "step:20--cost:5.0361--accuracy:%1.4898\n",
      "step:21--cost:4.9908--accuracy:%1.5934\n",
      "step:22--cost:4.8012--accuracy:%1.5661\n",
      "step:23--cost:4.7532--accuracy:%1.5371\n",
      "step:24--cost:4.6032--accuracy:%1.5316\n",
      "step:25--cost:4.5851--accuracy:%1.4680\n",
      "step:26--cost:4.4528--accuracy:%1.4753\n",
      "step:27--cost:4.3061--accuracy:%1.4807\n",
      "step:28--cost:4.2308--accuracy:%1.3499\n",
      "step:29--cost:4.1230--accuracy:%1.5661\n",
      "step:30--cost:3.9435--accuracy:%1.6097\n",
      "step:31--cost:3.8046--accuracy:%1.6134\n"
     ]
    }
   ],
   "source": [
    "train(test_gen, print_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(gen, batch_size, seq_len):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl, init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt')  \n",
    "    \n",
    "    step = 0 \n",
    "    cost = 0\n",
    "    accuracy = 0\n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: 1\n",
    "        }\n",
    "        \n",
    "        step_cost, step_accuracy = sess.run([cost_op, accuracy_op], feed_dict=feed_dict)\n",
    "        cost += step_cost\n",
    "        accuracy += step_accuracy\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    cost = cost / step\n",
    "    accuracy = accuracy / step\n",
    "    \n",
    "    print('cost:{0:.4f} -- accuracy:%{1:.4f}'.format(cost, accuracy * 100))\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set:\n",
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n",
      "cost:3.8221 -- accuracy:%15.9077\n"
     ]
    }
   ],
   "source": [
    "# print('train set:')\n",
    "# evaluate(train_gen, batch_size)\n",
    "print('dev set:')\n",
    "evaluate(dev_gen, 64, dev_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_word_from_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[1] = 0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(primes_list, top_n=5):\n",
    "    samples = primes_list.copy()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  tf.cast(tf.shape(input_pl)[0], tf.float32), 1)\n",
    "    init_state_op = init_zero_state_op\n",
    "    outputs_op, _, final_state_op = build_forward(cell_op, input_pl, init_state_op)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt') \n",
    "    \n",
    "    init_state = sess.run(init_state_op)\n",
    "    \n",
    "    for word in primes_list:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = word2index.get(word, 1)\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "    pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "    samples.append(index2word[pick_word_index])\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = pick_word_index\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "        pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "        pick_word = index2word[pick_word_index]\n",
    "        samples.append(pick_word)\n",
    "    \n",
    "        if pick_word == '。':\n",
    "            break\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'明天月。'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(primes_list=['明天'], top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(prime_sentence, top_n=5):\n",
    "    primes_list = list(jieba.cut(prime_sentence))\n",
    "    return sample(primes_list, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/n2/ndjtbc452y3c2qqh7g4wbly80000gn/T/jieba.cache\n",
      "Loading model cost 0.726 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'床前明月光，。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('床前明月光')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
