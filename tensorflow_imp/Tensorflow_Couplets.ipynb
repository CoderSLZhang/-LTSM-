{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "import helper\n",
    "from data_generator import CoupletsDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1000\n",
      "train_set shape: (766491, 52)\n",
      "dev_set shape: (4000, 40)\n",
      "test_set shape: (4000, 43)\n"
     ]
    }
   ],
   "source": [
    "vocab_size, index2word, word2index, train_set, dev_set, test_set = helper.process_dataset(vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq_len = train_set.shape[-1]\n",
    "dev_seq_len = dev_set.shape[-1]\n",
    "test_seq_len = test_set.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = CoupletsDataGenerator(train_set)\n",
    "dev_gen = CoupletsDataGenerator(dev_set)\n",
    "test_gen = CoupletsDataGenerator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    with tf.name_scope('input_placeholders'):\n",
    "        input = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input')\n",
    "        label = tf.placeholder(shape=(None, None), dtype=tf.int32, name='label')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "        \n",
    "    return input, label, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embeding_layer(input, vocab_size, embeding_dim):\n",
    "    with tf.name_scope('embeding_layer'):\n",
    "        embeding_matrix = tf.Variable(tf.random_uniform(shape=(vocab_size, embeding_dim),\n",
    "                                                        minval=-1, maxval=1, dtype=tf.float32),\n",
    "                                     name='embeding_matrix')\n",
    "        embeding = tf.nn.embedding_lookup(embeding_matrix, input, name='embed_lookup')\n",
    "        \n",
    "    return embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_cell(num_units, num_layers, keep_prob, batch_size):\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        def lstm():\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            dropout = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return dropout\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm() for _ in range(num_layers)])\n",
    "        init_zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(cell, embed_input, init_state):\n",
    "    with tf.name_scope('lstm_layer'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed_input, initial_state=init_state)\n",
    "        \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeding_dim = 200\n",
    "lstm_units = 64\n",
    "lstm_layers = 1\n",
    "keep_prob = 0.7\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "grad_clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward(cell, input, init_state):\n",
    "    embeding = build_embeding_layer(input, vocab_size, embeding_dim)\n",
    "    \n",
    "    outputs, final_state = build_lstm_layer(cell, embeding, init_state)\n",
    "    \n",
    "    logits = tf.layers.dense(outputs, vocab_size, name='fc_layer')\n",
    "    outputs = tf.nn.softmax(logits)\n",
    "    \n",
    "    return outputs, logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(cost, lr, grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(lr)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(outputs, labels):\n",
    "    predicts = tf.cast(tf.argmax(outputs, axis=-1), tf.int32)\n",
    "    predicts = tf.reshape(predicts, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    is_rights = tf.equal(predicts, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_rights, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen, lr=lr, batch_size=batch_size, epochs=epochs, \n",
    "          keep_prob=keep_prob, print_step=50):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, batch_size)\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl,\n",
    "                                                          init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    optimizer_op = build_optimizer(cost_op, lr, grad_clip)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0    \n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: keep_prob\n",
    "        }\n",
    "        \n",
    "        _, cost = sess.run([optimizer_op, cost_op],\n",
    "                                        feed_dict=feed_dict)\n",
    "        accuracy = accuracy_op.eval(feed_dict=feed_dict, session=sess)\n",
    "        \n",
    "        if step % print_step == 0:\n",
    "            print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step, cost, accuracy * 10))\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './model_save/model.ckpt')\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0--cost:6.9180--accuracy:%0.0073\n",
      "step:10--cost:6.1805--accuracy:%1.4408\n",
      "step:20--cost:5.2686--accuracy:%1.4662\n",
      "step:30--cost:4.1242--accuracy:%1.5498\n"
     ]
    }
   ],
   "source": [
    "train(test_gen, print_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(gen, batch_size, seq_len):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, batch_size)\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl, init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt')  \n",
    "    \n",
    "    step = 0 \n",
    "    cost = 0\n",
    "    accuracy = 0\n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: 1\n",
    "        }\n",
    "        \n",
    "        step_cost, step_accuracy = sess.run([cost_op, accuracy_op], feed_dict=feed_dict)\n",
    "        cost += step_cost\n",
    "        accuracy += step_accuracy\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    cost = cost / step\n",
    "    accuracy = accuracy / step\n",
    "    \n",
    "    print('cost:{0:.4f} -- accuracy:%{1:.4f}'.format(cost, accuracy * 100))\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set:\n",
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n",
      "cost:4.0873 -- accuracy:%15.9262\n"
     ]
    }
   ],
   "source": [
    "# print('train set:')\n",
    "# evaluate(train_gen, batch_size)\n",
    "print('dev set:')\n",
    "evaluate(dev_gen, 64, dev_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_word_from_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[1] = 0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(primes_list, top_n=5):\n",
    "    samples = primes_list.copy()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, 1)\n",
    "    init_state_op = init_zero_state_op\n",
    "    outputs_op, _, final_state_op = build_forward(cell_op, input_pl, init_state_op)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt') \n",
    "    \n",
    "    init_state = sess.run(init_state_op)\n",
    "    \n",
    "    for word in primes_list:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = word2index.get(word, 1)\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "    pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "    samples.append(index2word[pick_word_index])\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = pick_word_index\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "        pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "        pick_word = index2word[pick_word_index]\n",
    "        samples.append(pick_word)\n",
    "    \n",
    "        if pick_word == '。':\n",
    "            break\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'明天 ，   。'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(primes_list=['明天'], top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(prime_sentence, top_n=5):\n",
    "    primes_list = list(jieba.cut(prime_sentence))\n",
    "    return sample(primes_list, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'床前明月光；。'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('床前明月光')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
