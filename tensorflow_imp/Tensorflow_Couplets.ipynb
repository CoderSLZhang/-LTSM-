{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "import helper\n",
    "from data_generator import CoupletsDataGenerator\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets/tensorflow_imp\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/Desktop/AI-Play/Git/couplets\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1000\n",
      "train_set shape: (766491, 52)\n",
      "dev_set shape: (4000, 40)\n",
      "test_set shape: (4000, 43)\n"
     ]
    }
   ],
   "source": [
    "vocab_size, index2word, word2index, train_set, dev_set, test_set = helper.process_dataset(vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq_len = train_set.shape[-1]\n",
    "dev_seq_len = dev_set.shape[-1]\n",
    "test_seq_len = test_set.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = CoupletsDataGenerator(train_set)\n",
    "dev_gen = CoupletsDataGenerator(dev_set)\n",
    "test_gen = CoupletsDataGenerator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    with tf.name_scope('input_placeholders'):\n",
    "        input = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input')\n",
    "        label = tf.placeholder(shape=(None, None), dtype=tf.int32, name='label')\n",
    "        keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "        \n",
    "    return input, label, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embeding_layer(input, vocab_size, embeding_dim):\n",
    "    with tf.name_scope('embeding_layer'):\n",
    "        embeding_matrix = tf.Variable(tf.random_uniform(shape=(vocab_size, embeding_dim),\n",
    "                                                        minval=-1, maxval=1, dtype=tf.float32),\n",
    "                                     name='embeding_matrix')\n",
    "        embeding = tf.nn.embedding_lookup(embeding_matrix, input, name='embed_lookup')\n",
    "        \n",
    "    return embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_cell(num_units, num_layers, keep_prob, batch_size):\n",
    "    with tf.name_scope('lstm_cell'):\n",
    "        def lstm():\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "            dropout = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return dropout\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm() for _ in range(num_layers)])\n",
    "        init_zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(cell, embed_input, init_state):\n",
    "    with tf.name_scope('lstm_layer'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed_input, initial_state=init_state)\n",
    "        \n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeding_dim = 200\n",
    "lstm_units = 64\n",
    "lstm_layers = 1\n",
    "keep_prob = 0.7\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "grad_clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward(cell, input, init_state):\n",
    "    embeding = build_embeding_layer(input, vocab_size, embeding_dim)\n",
    "    \n",
    "    outputs, final_state = build_lstm_layer(cell, embeding, init_state)\n",
    "    \n",
    "    logits = tf.layers.dense(outputs, vocab_size, name='fc_layer')\n",
    "    outputs = tf.nn.softmax(logits)\n",
    "    \n",
    "    return outputs, logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(cost, lr, grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(lr)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(outputs, labels):\n",
    "    predicts = tf.cast(tf.argmax(outputs, axis=-1), tf.int32)\n",
    "    predicts = tf.reshape(predicts, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    is_rights = tf.equal(predicts, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_rights, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen, lr=lr, batch_size=batch_size, epochs=epochs, \n",
    "          keep_prob=keep_prob, print_step=50):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl,\n",
    "                                                          init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    optimizer_op = build_optimizer(cost_op, lr, grad_clip)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    costs = []\n",
    "    step = 0    \n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: keep_prob\n",
    "        }\n",
    "        \n",
    "        _, cost = sess.run([optimizer_op, cost_op],\n",
    "                                        feed_dict=feed_dict)\n",
    "        accuracy = accuracy_op.eval(feed_dict=feed_dict, session=sess)\n",
    "        \n",
    "        if step % print_step == 0:\n",
    "            print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step, cost, accuracy * 10))\n",
    "            costs.append(cost)\n",
    "            \n",
    "        step += 1\n",
    "    \n",
    "#     if step % print_step != 0:\n",
    "#         print('step:{0}--cost:{1:.4f}--accuracy:%{2:.4f}'.format(step, cost, accuracy * 10))\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './model_save/model.ckpt')\n",
    "        \n",
    "    sess.close()\n",
    "    \n",
    "    plt.plot(range(0, step, print_step), costs)\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0--cost:6.9004--accuracy:%0.1326\n",
      "step:2--cost:6.7580--accuracy:%1.0992\n",
      "step:4--cost:6.5789--accuracy:%1.4117\n",
      "step:6--cost:6.4396--accuracy:%1.4299\n",
      "step:8--cost:6.2487--accuracy:%1.5461\n",
      "step:10--cost:6.1480--accuracy:%1.4644\n",
      "step:12--cost:5.9066--accuracy:%1.5716\n",
      "step:14--cost:5.7616--accuracy:%1.5080\n",
      "step:16--cost:5.5202--accuracy:%1.5716\n",
      "step:18--cost:5.2583--accuracy:%1.5643\n",
      "step:20--cost:5.0199--accuracy:%1.6097\n",
      "step:22--cost:4.8117--accuracy:%1.5807\n",
      "step:24--cost:4.6815--accuracy:%1.5389\n",
      "step:26--cost:4.3770--accuracy:%1.4644\n",
      "step:28--cost:4.1819--accuracy:%1.4680\n",
      "step:30--cost:4.0165--accuracy:%1.4771\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c67a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(test_gen, print_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(gen, batch_size, seq_len):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  keep_prob, tf.shape(input_pl)[0])\n",
    "        \n",
    "    outputs_op, logits_op, final_state_op = build_forward(cell_op, input_pl, init_zero_state_op)\n",
    "    \n",
    "    loss_weight_op = tf.where(tf.equal(input_pl, 0), \n",
    "                              tf.zeros_like(input_pl, dtype=tf.float32),\n",
    "                              tf.ones_like(input_pl, dtype=tf.float32))\n",
    "    cost_op = seq2seq.sequence_loss(logits_op, label_pl, loss_weight_op)\n",
    "    \n",
    "    accuracy_op = cal_accuracy(outputs_op, label_pl)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt')  \n",
    "    \n",
    "    step = 0 \n",
    "    cost = 0\n",
    "    accuracy = 0\n",
    "    for X, Y in gen.get_batch(sess, batch_size, epochs):\n",
    "        feed_dict = {\n",
    "            input_pl: X,\n",
    "            label_pl: Y,\n",
    "            keep_prob_pl: 1\n",
    "        }\n",
    "        \n",
    "        step_cost, step_accuracy = sess.run([cost_op, accuracy_op], feed_dict=feed_dict)\n",
    "        cost += step_cost\n",
    "        accuracy += step_accuracy\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    cost = cost / step\n",
    "    accuracy = accuracy / step\n",
    "    \n",
    "    print('cost:{0:.4f} -- accuracy:%{1:.4f}'.format(cost, accuracy * 100))\n",
    "        \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set:\n",
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n",
      "cost:3.8221 -- accuracy:%15.9077\n"
     ]
    }
   ],
   "source": [
    "# print('train set:')\n",
    "# evaluate(train_gen, batch_size)\n",
    "print('dev set:')\n",
    "evaluate(dev_gen, 64, dev_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_word_from_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[1] = 0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(primes_list, top_n=5):\n",
    "    samples = primes_list.copy()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    input_pl, label_pl, keep_prob_pl = build_inputs()\n",
    "    cell_op, init_zero_state_op = build_lstm_cell(lstm_units, lstm_layers, \n",
    "                                                  tf.cast(tf.shape(input_pl)[0], tf.float32), 1)\n",
    "    init_state_op = init_zero_state_op\n",
    "    outputs_op, _, final_state_op = build_forward(cell_op, input_pl, init_state_op)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model_save/model.ckpt') \n",
    "    \n",
    "    init_state = sess.run(init_state_op)\n",
    "    \n",
    "    for word in primes_list:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = word2index.get(word, 1)\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "    pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "    samples.append(index2word[pick_word_index])\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, 1), dtype=np.int32)\n",
    "        x[0, 0] = pick_word_index\n",
    "        \n",
    "        feed_dict = {\n",
    "            input_pl: x,\n",
    "            keep_prob_pl: 1,\n",
    "            init_state_op: init_state\n",
    "        }\n",
    "        \n",
    "        outputs, final_state = sess.run([outputs_op, final_state_op], feed_dict=feed_dict)\n",
    "        init_state = final_state\n",
    "        \n",
    "        pick_word_index = pick_word_from_top_n(outputs, vocab_size, top_n)\n",
    "        pick_word = index2word[pick_word_index]\n",
    "        samples.append(pick_word)\n",
    "    \n",
    "        if pick_word == '。':\n",
    "            break\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'明天月。'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(primes_list=['明天'], top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(prime_sentence, top_n=5):\n",
    "    primes_list = list(jieba.cut(prime_sentence))\n",
    "    return sample(primes_list, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/n2/ndjtbc452y3c2qqh7g4wbly80000gn/T/jieba.cache\n",
      "Loading model cost 0.726 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'床前明月光，。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('床前明月光')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
