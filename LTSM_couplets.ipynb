{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangshulin_work/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from couplets_utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_A = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = load_sample_datasets(vocabs_size=2000, max_len=30, batch_size=16, sample_size=1000, n_a=N_A)\n",
    "sample_gen = sample['sample_gen']\n",
    "index2word = sample['index2word']\n",
    "word2index = sample['word2index']\n",
    "vocabs_size = sample['vocabs_size']\n",
    "max_len = sample['max_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_gen length : 63\n"
     ]
    }
   ],
   "source": [
    "print('sample_gen length :', len(sample_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_model(n_x, n_a, Tx, keep_prob=0.5):    \n",
    "    input = Input(shape=(Tx, n_x), name='x0')\n",
    "    a_0_0 = Input(shape=(n_a,), name='a_0_0')\n",
    "    c_0_0 = Input(shape=(n_a,), name='c_0_0')\n",
    "    a_1_0 = Input(shape=(n_a,), name='a_1_0')\n",
    "    c_1_0 = Input(shape=(n_a,), name='c_1_0')\n",
    "        \n",
    "    a_0 = a_0_0\n",
    "    c_0 = c_0_0\n",
    "    a_1 = a_1_0\n",
    "    c_1 = c_1_0\n",
    "    \n",
    "    lstm_cell_0 = LSTM(units=n_a, return_state=True, name='lstm_0')\n",
    "    lstm_cell_1 = LSTM(units=n_a, return_state=True, name='lstm_1')\n",
    "    dense_layer_2 = Dense(units=n_x, activation='softmax', name='softmax_2')\n",
    "        \n",
    "    outputs = []\n",
    "        \n",
    "    for i in range(Tx):\n",
    "        x = Lambda(lambda j: j[:, i, :])(input)\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_0, x, c_0 = lstm_cell_0(x, initial_state=[a_0, c_0])\n",
    "        x = Dropout(rate=1-keep_prob)(x)\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_1, x, c_1 = lstm_cell_1(x, initial_state=[a_1, c_1])\n",
    "        x = Dropout(rate=1-keep_prob)(x)\n",
    "        x = dense_layer_2(x)\n",
    "        outputs.append(x)\n",
    "                            \n",
    "    model = Model(inputs=[input, a_0_0, c_0_0, a_1_0, c_1_0], outputs=outputs)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = create_train_model(vocabs_size, N_A, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "63/63 [==============================] - 36s 571ms/step - loss: 157.3878 - softmax_2_loss_1: 7.5608 - softmax_2_loss_2: 7.5134 - softmax_2_loss_3: 7.4060 - softmax_2_loss_4: 7.2196 - softmax_2_loss_5: 6.8515 - softmax_2_loss_6: 7.1226 - softmax_2_loss_7: 7.6629 - softmax_2_loss_8: 5.8958 - softmax_2_loss_9: 7.6804 - softmax_2_loss_10: 7.5493 - softmax_2_loss_11: 7.5136 - softmax_2_loss_12: 7.2818 - softmax_2_loss_13: 6.6289 - softmax_2_loss_14: 6.8460 - softmax_2_loss_15: 6.7875 - softmax_2_loss_16: 5.0992 - softmax_2_loss_17: 3.9335 - softmax_2_loss_18: 3.5774 - softmax_2_loss_19: 3.9296 - softmax_2_loss_20: 3.6571 - softmax_2_loss_21: 3.6758 - softmax_2_loss_22: 3.5773 - softmax_2_loss_23: 3.5363 - softmax_2_loss_24: 3.3556 - softmax_2_loss_25: 3.2804 - softmax_2_loss_26: 2.8353 - softmax_2_loss_27: 2.5079 - softmax_2_loss_28: 2.3868 - softmax_2_loss_29: 2.2817 - softmax_2_loss_30: 2.2337 - softmax_2_acc_1: 0.0000e+00 - softmax_2_acc_2: 0.0000e+00 - softmax_2_acc_3: 0.0000e+00 - softmax_2_acc_4: 0.0000e+00 - softmax_2_acc_5: 0.0030 - softmax_2_acc_6: 0.0030 - softmax_2_acc_7: 0.0149 - softmax_2_acc_8: 0.0149 - softmax_2_acc_9: 0.0268 - softmax_2_acc_10: 0.0268 - softmax_2_acc_11: 0.0456 - softmax_2_acc_12: 0.0456 - softmax_2_acc_13: 0.1458 - softmax_2_acc_14: 0.1468 - softmax_2_acc_15: 0.1607 - softmax_2_acc_16: 0.1617 - softmax_2_acc_17: 0.6925 - softmax_2_acc_18: 0.6915 - softmax_2_acc_19: 0.6994 - softmax_2_acc_20: 0.7014 - softmax_2_acc_21: 0.7401 - softmax_2_acc_22: 0.7381 - softmax_2_acc_23: 0.7659 - softmax_2_acc_24: 0.7639 - softmax_2_acc_25: 0.7937 - softmax_2_acc_26: 0.7927 - softmax_2_acc_27: 0.9296 - softmax_2_acc_28: 0.9266 - softmax_2_acc_29: 0.9673 - softmax_2_acc_30: 0.9663          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127c98cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit_generator(sample_gen, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model.save_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_infer_model(n_x, n_a, Tx):\n",
    "    input = Input(shape=(Tx, n_x), name='x0')\n",
    "    a_0_0 = Input(shape=(n_a,), name='a_0_0')\n",
    "    c_0_0 = Input(shape=(n_a,), name='c_0_0')\n",
    "    a_1_0 = Input(shape=(n_a,), name='a_1_0')\n",
    "    c_1_0 = Input(shape=(n_a,), name='c_1_0')\n",
    "    \n",
    "    x = Lambda(lambda x: x[:, 0, :])(input)\n",
    "    a_0 = a_0_0\n",
    "    c_0 = c_0_0\n",
    "    a_1 = a_1_0\n",
    "    c_1 = c_1_0\n",
    "\n",
    "    lstm_cell_0 = LSTM(units=n_a, return_state=True, name='lstm_0')\n",
    "    lstm_cell_1 = LSTM(units=n_a, return_state=True, name='lstm_1')\n",
    "    dense_layer_2 = Dense(units=n_x, activation='softmax', name='softmax_2')\n",
    "    \n",
    "    def one_hot(x):\n",
    "        x = K.argmax(x)\n",
    "        x = tf.one_hot(x, n_x) \n",
    "        return x\n",
    "    \n",
    "    def select_x(x, i):\n",
    "        return tf.cond(\n",
    "            tf.equal(tf.reduce_sum(input[:, i+1, :]), 0),\n",
    "            lambda : x,\n",
    "            lambda : input[:, i+1, :]\n",
    "        )\n",
    "        \n",
    "    def select_output(x, i):\n",
    "        return tf.cond(\n",
    "            tf.less(i + 1, Tx),\n",
    "            lambda : select_x(x, i),\n",
    "            lambda : x\n",
    "        )\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(Tx - 1):              \n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_0, x, c_0 = lstm_cell_0(x, initial_state=[a_0, c_0])\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a_1, x, c_1 = lstm_cell_1(x, initial_state=[a_1, c_1])\n",
    "        x = dense_layer_2(x)\n",
    "        x = Lambda(one_hot)(x)\n",
    "        \n",
    "        x = Lambda(lambda x: select_output(x, i))(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "        \n",
    "    model = Model(inputs=[input, a_0_0, c_0_0, a_1_0, c_1_0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model = create_infer_model(vocabs_size, N_A, max_len)\n",
    "infer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model.load_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_couplets(begin_text, infer_model):\n",
    "    x = convert_text_to_onehot(begin_text, vocabs_size, max_len, word2index)\n",
    "    a_0 = np.zeros((1, N_A))\n",
    "    c_0 = np.zeros((1, N_A))\n",
    "    a_1 = np.zeros((1, N_A))\n",
    "    c_1 = np.zeros((1, N_A))\n",
    "    \n",
    "    result = infer_model.predict([x, a_0, c_0, a_1, c_1])\n",
    "    result_text = convert_predict_to_text(np.array(result), index2word)\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天天向上                         \n"
     ]
    }
   ],
   "source": [
    "text = '天天向上'\n",
    "result_text = write_couplets(text, infer_model)\n",
    "print(result_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
