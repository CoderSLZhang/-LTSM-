{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from couplets_utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = load_sample_datasets(vocabs_size=2000, max_len=30, batch_size=16, sample_size=1000, n_a=N_A)\n",
    "sample_gen = sample['sample_gen']\n",
    "index2word = sample['index2word']\n",
    "word2index = sample['word2index']\n",
    "vocabs_size = sample['vocabs_size']\n",
    "max_len = sample['max_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_gen length : 63\n"
     ]
    }
   ],
   "source": [
    "print('sample_gen length :', len(sample_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_model(n_x, n_a, Tx):\n",
    "    input = Input(shape=(Tx, n_x), name='x0')\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "        \n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    lstm_cell = LSTM(units=n_a, return_state=True, name='lstm_0')\n",
    "    dense_layer = Dense(units=n_x, activation='softmax', name='softmax_1')\n",
    "        \n",
    "    outputs = []\n",
    "        \n",
    "    for i in range(Tx):\n",
    "        x = Lambda(lambda j: j[:, i, :])(input)\n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a, x, c = lstm_cell(x, initial_state=[a, c])\n",
    "        x = dense_layer(x)\n",
    "        outputs.append(x)\n",
    "                            \n",
    "    model = Model(inputs=[input, a0, c0], outputs=outputs)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = create_train_model(vocabs_size, N_A, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 44s 703ms/step - loss: 161.2220 - softmax_1_loss: 2.6458 - softmax_1_acc: 0.0000e+00 - softmax_1_acc_1: 0.0000e+00 - softmax_1_acc_2: 0.0000e+00 - softmax_1_acc_3: 0.0000e+00 - softmax_1_acc_4: 9.9219e-04 - softmax_1_acc_5: 9.9219e-04 - softmax_1_acc_6: 0.0298 - softmax_1_acc_7: 0.0318 - softmax_1_acc_8: 0.0337 - softmax_1_acc_9: 0.0347 - softmax_1_acc_10: 0.0496 - softmax_1_acc_11: 0.0486 - softmax_1_acc_12: 0.1637 - softmax_1_acc_13: 0.1647 - softmax_1_acc_14: 0.1786 - softmax_1_acc_15: 0.1786 - softmax_1_acc_16: 0.6885 - softmax_1_acc_17: 0.6925 - softmax_1_acc_18: 0.6954 - softmax_1_acc_19: 0.6974 - softmax_1_acc_20: 0.7371 - softmax_1_acc_21: 0.7371 - softmax_1_acc_22: 0.7629 - softmax_1_acc_23: 0.7629 - softmax_1_acc_24: 0.7837 - softmax_1_acc_25: 0.7837 - softmax_1_acc_26: 0.9068 - softmax_1_acc_27: 0.9078 - softmax_1_acc_28: 0.9504 - softmax_1_acc_29: 0.9514\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 129.0984 - softmax_1_loss: 0.6354 - softmax_1_acc: 0.0000e+00 - softmax_1_acc_1: 0.0000e+00 - softmax_1_acc_2: 0.0000e+00 - softmax_1_acc_3: 0.0000e+00 - softmax_1_acc_4: 9.9219e-04 - softmax_1_acc_5: 9.9219e-04 - softmax_1_acc_6: 0.0298 - softmax_1_acc_7: 0.0298 - softmax_1_acc_8: 0.0357 - softmax_1_acc_9: 0.0357 - softmax_1_acc_10: 0.0496 - softmax_1_acc_11: 0.0496 - softmax_1_acc_12: 0.1756 - softmax_1_acc_13: 0.1756 - softmax_1_acc_14: 0.1895 - softmax_1_acc_15: 0.1895 - softmax_1_acc_16: 0.7262 - softmax_1_acc_17: 0.7262 - softmax_1_acc_18: 0.7282 - softmax_1_acc_19: 0.7282 - softmax_1_acc_20: 0.7659 - softmax_1_acc_21: 0.7659 - softmax_1_acc_22: 0.7937 - softmax_1_acc_23: 0.7937 - softmax_1_acc_24: 0.8145 - softmax_1_acc_25: 0.8145 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9405 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9841\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 123.2398 - softmax_1_loss: 0.3764 - softmax_1_acc: 0.0000e+00 - softmax_1_acc_1: 0.0000e+00 - softmax_1_acc_2: 0.0050 - softmax_1_acc_3: 0.0020 - softmax_1_acc_4: 0.0040 - softmax_1_acc_5: 0.0308 - softmax_1_acc_6: 0.0318 - softmax_1_acc_7: 0.1062 - softmax_1_acc_8: 0.0357 - softmax_1_acc_9: 0.0377 - softmax_1_acc_10: 0.0526 - softmax_1_acc_11: 0.0516 - softmax_1_acc_12: 0.1766 - softmax_1_acc_13: 0.1756 - softmax_1_acc_14: 0.1895 - softmax_1_acc_15: 0.1895 - softmax_1_acc_16: 0.7262 - softmax_1_acc_17: 0.7262 - softmax_1_acc_18: 0.7282 - softmax_1_acc_19: 0.7282 - softmax_1_acc_20: 0.7659 - softmax_1_acc_21: 0.7659 - softmax_1_acc_22: 0.7937 - softmax_1_acc_23: 0.7937 - softmax_1_acc_24: 0.8145 - softmax_1_acc_25: 0.8145 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9405 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9841\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 117.8880 - softmax_1_loss: 0.1654 - softmax_1_acc: 0.0000e+00 - softmax_1_acc_1: 9.9219e-04 - softmax_1_acc_2: 0.0228 - softmax_1_acc_3: 0.0060 - softmax_1_acc_4: 0.0149 - softmax_1_acc_5: 0.1151 - softmax_1_acc_6: 0.0337 - softmax_1_acc_7: 0.4752 - softmax_1_acc_8: 0.0367 - softmax_1_acc_9: 0.0675 - softmax_1_acc_10: 0.0734 - softmax_1_acc_11: 0.0625 - softmax_1_acc_12: 0.2371 - softmax_1_acc_13: 0.1875 - softmax_1_acc_14: 0.1954 - softmax_1_acc_15: 0.1895 - softmax_1_acc_16: 0.7262 - softmax_1_acc_17: 0.7262 - softmax_1_acc_18: 0.7282 - softmax_1_acc_19: 0.7282 - softmax_1_acc_20: 0.7649 - softmax_1_acc_21: 0.7659 - softmax_1_acc_22: 0.7937 - softmax_1_acc_23: 0.7937 - softmax_1_acc_24: 0.8145 - softmax_1_acc_25: 0.8145 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9405 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9841\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 24s 375ms/step - loss: 114.6394 - softmax_1_loss: 0.1194 - softmax_1_acc: 0.0000e+00 - softmax_1_acc_1: 0.0258 - softmax_1_acc_2: 0.0248 - softmax_1_acc_3: 0.0060 - softmax_1_acc_4: 0.0149 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0427 - softmax_1_acc_7: 0.5645 - softmax_1_acc_8: 0.0367 - softmax_1_acc_9: 0.0734 - softmax_1_acc_10: 0.0774 - softmax_1_acc_11: 0.0704 - softmax_1_acc_12: 0.3006 - softmax_1_acc_13: 0.2113 - softmax_1_acc_14: 0.2034 - softmax_1_acc_15: 0.1895 - softmax_1_acc_16: 0.7262 - softmax_1_acc_17: 0.7262 - softmax_1_acc_18: 0.7282 - softmax_1_acc_19: 0.7282 - softmax_1_acc_20: 0.7659 - softmax_1_acc_21: 0.7659 - softmax_1_acc_22: 0.7937 - softmax_1_acc_23: 0.7937 - softmax_1_acc_24: 0.8145 - softmax_1_acc_25: 0.8145 - softmax_1_acc_26: 0.9385 - softmax_1_acc_27: 0.9405 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9841\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 21s 340ms/step - loss: 112.5072 - softmax_1_loss: 0.0859 - softmax_1_acc: 0.0139 - softmax_1_acc_1: 0.0129 - softmax_1_acc_2: 0.0109 - softmax_1_acc_3: 0.0060 - softmax_1_acc_4: 0.0149 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0407 - softmax_1_acc_7: 0.5665 - softmax_1_acc_8: 0.0367 - softmax_1_acc_9: 0.0734 - softmax_1_acc_10: 0.0774 - softmax_1_acc_11: 0.0804 - softmax_1_acc_12: 0.2996 - softmax_1_acc_13: 0.2182 - softmax_1_acc_14: 0.2044 - softmax_1_acc_15: 0.2093 - softmax_1_acc_16: 0.7262 - softmax_1_acc_17: 0.7262 - softmax_1_acc_18: 0.7282 - softmax_1_acc_19: 0.7361 - softmax_1_acc_20: 0.7659 - softmax_1_acc_21: 0.7699 - softmax_1_acc_22: 0.7937 - softmax_1_acc_23: 0.7947 - softmax_1_acc_24: 0.8145 - softmax_1_acc_25: 0.8155 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9405 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9851\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 22s 341ms/step - loss: 110.6727 - softmax_1_loss: 0.0714 - softmax_1_acc: 0.0387 - softmax_1_acc_1: 0.0417 - softmax_1_acc_2: 0.0040 - softmax_1_acc_3: 0.0060 - softmax_1_acc_4: 0.0149 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0437 - softmax_1_acc_7: 0.5665 - softmax_1_acc_8: 0.0377 - softmax_1_acc_9: 0.0774 - softmax_1_acc_10: 0.0764 - softmax_1_acc_11: 0.1131 - softmax_1_acc_12: 0.3016 - softmax_1_acc_13: 0.2202 - softmax_1_acc_14: 0.2054 - softmax_1_acc_15: 0.2728 - softmax_1_acc_16: 0.7242 - softmax_1_acc_17: 0.7272 - softmax_1_acc_18: 0.7282 - softmax_1_acc_19: 0.7470 - softmax_1_acc_20: 0.7619 - softmax_1_acc_21: 0.7748 - softmax_1_acc_22: 0.7927 - softmax_1_acc_23: 0.8026 - softmax_1_acc_24: 0.8145 - softmax_1_acc_25: 0.8453 - softmax_1_acc_26: 0.9365 - softmax_1_acc_27: 0.9465 - softmax_1_acc_28: 0.9811 - softmax_1_acc_29: 0.9851\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 22s 342ms/step - loss: 109.6865 - softmax_1_loss: 0.0520 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0069 - softmax_1_acc_3: 0.0129 - softmax_1_acc_4: 0.0139 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0446 - softmax_1_acc_7: 0.5665 - softmax_1_acc_8: 0.0387 - softmax_1_acc_9: 0.0794 - softmax_1_acc_10: 0.0804 - softmax_1_acc_11: 0.1458 - softmax_1_acc_12: 0.3016 - softmax_1_acc_13: 0.2282 - softmax_1_acc_14: 0.2093 - softmax_1_acc_15: 0.3889 - softmax_1_acc_16: 0.7292 - softmax_1_acc_17: 0.7381 - softmax_1_acc_18: 0.7322 - softmax_1_acc_19: 0.7649 - softmax_1_acc_20: 0.7679 - softmax_1_acc_21: 0.7818 - softmax_1_acc_22: 0.7917 - softmax_1_acc_23: 0.8026 - softmax_1_acc_24: 0.8135 - softmax_1_acc_25: 0.8502 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9474 - softmax_1_acc_28: 0.9831 - softmax_1_acc_29: 0.9901\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 22s 349ms/step - loss: 108.6205 - softmax_1_loss: 0.0403 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0337 - softmax_1_acc_3: 0.0149 - softmax_1_acc_4: 0.0189 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0456 - softmax_1_acc_7: 0.5685 - softmax_1_acc_8: 0.0387 - softmax_1_acc_9: 0.0804 - softmax_1_acc_10: 0.0774 - softmax_1_acc_11: 0.1667 - softmax_1_acc_12: 0.3036 - softmax_1_acc_13: 0.2282 - softmax_1_acc_14: 0.2183 - softmax_1_acc_15: 0.4940 - softmax_1_acc_16: 0.7361 - softmax_1_acc_17: 0.7708 - softmax_1_acc_18: 0.7331 - softmax_1_acc_19: 0.7679 - softmax_1_acc_20: 0.7659 - softmax_1_acc_21: 0.7897 - softmax_1_acc_22: 0.7937 - softmax_1_acc_23: 0.8066 - softmax_1_acc_24: 0.8155 - softmax_1_acc_25: 0.8790 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9643 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9911\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 107.7322 - softmax_1_loss: 0.0307 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0337 - softmax_1_acc_3: 0.0169 - softmax_1_acc_4: 0.0218 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0446 - softmax_1_acc_7: 0.5685 - softmax_1_acc_8: 0.0377 - softmax_1_acc_9: 0.0833 - softmax_1_acc_10: 0.0774 - softmax_1_acc_11: 0.1786 - softmax_1_acc_12: 0.3036 - softmax_1_acc_13: 0.2331 - softmax_1_acc_14: 0.2331 - softmax_1_acc_15: 0.6042 - softmax_1_acc_16: 0.7451 - softmax_1_acc_17: 0.8363 - softmax_1_acc_18: 0.7371 - softmax_1_acc_19: 0.7946 - softmax_1_acc_20: 0.7699 - softmax_1_acc_21: 0.7976 - softmax_1_acc_22: 0.7976 - softmax_1_acc_23: 0.8135 - softmax_1_acc_24: 0.8165 - softmax_1_acc_25: 0.9068 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9703 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9960\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 107.3025 - softmax_1_loss: 0.0320 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0357 - softmax_1_acc_3: 0.0298 - softmax_1_acc_4: 0.0377 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0466 - softmax_1_acc_7: 0.5704 - softmax_1_acc_8: 0.0407 - softmax_1_acc_9: 0.0883 - softmax_1_acc_10: 0.0804 - softmax_1_acc_11: 0.1935 - softmax_1_acc_12: 0.3095 - softmax_1_acc_13: 0.2361 - softmax_1_acc_14: 0.2232 - softmax_1_acc_15: 0.6409 - softmax_1_acc_16: 0.7451 - softmax_1_acc_17: 0.8264 - softmax_1_acc_18: 0.7381 - softmax_1_acc_19: 0.7887 - softmax_1_acc_20: 0.7689 - softmax_1_acc_21: 0.7976 - softmax_1_acc_22: 0.7996 - softmax_1_acc_23: 0.8086 - softmax_1_acc_24: 0.8195 - softmax_1_acc_25: 0.9187 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9732 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9980\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 106.5220 - softmax_1_loss: 0.0234 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0308 - softmax_1_acc_4: 0.0714 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0466 - softmax_1_acc_7: 0.5714 - softmax_1_acc_8: 0.0417 - softmax_1_acc_9: 0.0883 - softmax_1_acc_10: 0.0824 - softmax_1_acc_11: 0.1974 - softmax_1_acc_12: 0.3075 - softmax_1_acc_13: 0.2371 - softmax_1_acc_14: 0.2371 - softmax_1_acc_15: 0.7064 - softmax_1_acc_16: 0.7441 - softmax_1_acc_17: 0.8482 - softmax_1_acc_18: 0.7381 - softmax_1_acc_19: 0.8036 - softmax_1_acc_20: 0.7738 - softmax_1_acc_21: 0.7947 - softmax_1_acc_22: 0.8006 - softmax_1_acc_23: 0.8175 - softmax_1_acc_24: 0.8165 - softmax_1_acc_25: 0.9336 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9811 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9970\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 22s 356ms/step - loss: 105.8074 - softmax_1_loss: 0.0267 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0228 - softmax_1_acc_4: 0.1359 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0476 - softmax_1_acc_7: 0.5734 - softmax_1_acc_8: 0.0407 - softmax_1_acc_9: 0.0863 - softmax_1_acc_10: 0.0784 - softmax_1_acc_11: 0.1974 - softmax_1_acc_12: 0.3085 - softmax_1_acc_13: 0.2361 - softmax_1_acc_14: 0.2421 - softmax_1_acc_15: 0.7441 - softmax_1_acc_16: 0.7470 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7381 - softmax_1_acc_19: 0.8055 - softmax_1_acc_20: 0.7738 - softmax_1_acc_21: 0.8016 - softmax_1_acc_22: 0.8016 - softmax_1_acc_23: 0.8155 - softmax_1_acc_24: 0.8195 - softmax_1_acc_25: 0.9385 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9811 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9990\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 24s 386ms/step - loss: 104.9896 - softmax_1_loss: 0.0176 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0417 - softmax_1_acc_4: 0.1458 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0466 - softmax_1_acc_7: 0.5744 - softmax_1_acc_8: 0.0417 - softmax_1_acc_9: 0.0883 - softmax_1_acc_10: 0.0804 - softmax_1_acc_11: 0.2034 - softmax_1_acc_12: 0.3075 - softmax_1_acc_13: 0.2371 - softmax_1_acc_14: 0.2411 - softmax_1_acc_15: 0.7470 - softmax_1_acc_16: 0.7460 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7411 - softmax_1_acc_19: 0.8055 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8016 - softmax_1_acc_22: 0.8016 - softmax_1_acc_23: 0.8175 - softmax_1_acc_24: 0.8185 - softmax_1_acc_25: 0.9405 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9831 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 104.4285 - softmax_1_loss: 0.0138 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0317 - softmax_1_acc_4: 0.1974 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0466 - softmax_1_acc_7: 0.5754 - softmax_1_acc_8: 0.0427 - softmax_1_acc_9: 0.0873 - softmax_1_acc_10: 0.0814 - softmax_1_acc_11: 0.2024 - softmax_1_acc_12: 0.3135 - softmax_1_acc_13: 0.2440 - softmax_1_acc_14: 0.2411 - softmax_1_acc_15: 0.7470 - softmax_1_acc_16: 0.7460 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7401 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8016 - softmax_1_acc_22: 0.8036 - softmax_1_acc_23: 0.8195 - softmax_1_acc_24: 0.8195 - softmax_1_acc_25: 0.9395 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 24s 377ms/step - loss: 104.0680 - softmax_1_loss: 0.0167 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0208 - softmax_1_acc_4: 0.1954 - softmax_1_acc_5: 0.1270 - softmax_1_acc_6: 0.0476 - softmax_1_acc_7: 0.5744 - softmax_1_acc_8: 0.0417 - softmax_1_acc_9: 0.0893 - softmax_1_acc_10: 0.0814 - softmax_1_acc_11: 0.2044 - softmax_1_acc_12: 0.3085 - softmax_1_acc_13: 0.2470 - softmax_1_acc_14: 0.2421 - softmax_1_acc_15: 0.7480 - softmax_1_acc_16: 0.7460 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7401 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8016 - softmax_1_acc_22: 0.8016 - softmax_1_acc_23: 0.8175 - softmax_1_acc_24: 0.8205 - softmax_1_acc_25: 0.9405 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 25s 391ms/step - loss: 103.4092 - softmax_1_loss: 0.0105 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0367 - softmax_1_acc_3: 0.0169 - softmax_1_acc_4: 0.1945 - softmax_1_acc_5: 0.1339 - softmax_1_acc_6: 0.0456 - softmax_1_acc_7: 0.5734 - softmax_1_acc_8: 0.0427 - softmax_1_acc_9: 0.0923 - softmax_1_acc_10: 0.0883 - softmax_1_acc_11: 0.2074 - softmax_1_acc_12: 0.3224 - softmax_1_acc_13: 0.2520 - softmax_1_acc_14: 0.2441 - softmax_1_acc_15: 0.7480 - softmax_1_acc_16: 0.7470 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7411 - softmax_1_acc_19: 0.8055 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8006 - softmax_1_acc_22: 0.8026 - softmax_1_acc_23: 0.8204 - softmax_1_acc_24: 0.8205 - softmax_1_acc_25: 0.9395 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 336ms/step - loss: 102.6913 - softmax_1_loss: 0.0093 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0407 - softmax_1_acc_3: 0.0169 - softmax_1_acc_4: 0.1945 - softmax_1_acc_5: 0.1597 - softmax_1_acc_6: 0.0466 - softmax_1_acc_7: 0.5734 - softmax_1_acc_8: 0.0417 - softmax_1_acc_9: 0.0962 - softmax_1_acc_10: 0.0953 - softmax_1_acc_11: 0.2153 - softmax_1_acc_12: 0.3244 - softmax_1_acc_13: 0.2490 - softmax_1_acc_14: 0.2441 - softmax_1_acc_15: 0.7500 - softmax_1_acc_16: 0.7480 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7411 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7778 - softmax_1_acc_21: 0.8016 - softmax_1_acc_22: 0.8066 - softmax_1_acc_23: 0.8195 - softmax_1_acc_24: 0.8205 - softmax_1_acc_25: 0.9405 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 102.1104 - softmax_1_loss: 0.0102 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0218 - softmax_1_acc_4: 0.1925 - softmax_1_acc_5: 0.1776 - softmax_1_acc_6: 0.0476 - softmax_1_acc_7: 0.5734 - softmax_1_acc_8: 0.0417 - softmax_1_acc_9: 0.0982 - softmax_1_acc_10: 0.0953 - softmax_1_acc_11: 0.2173 - softmax_1_acc_12: 0.3214 - softmax_1_acc_13: 0.2559 - softmax_1_acc_14: 0.2451 - softmax_1_acc_15: 0.7530 - softmax_1_acc_16: 0.7470 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7401 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7778 - softmax_1_acc_21: 0.8026 - softmax_1_acc_22: 0.8036 - softmax_1_acc_23: 0.8215 - softmax_1_acc_24: 0.8215 - softmax_1_acc_25: 0.9405 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 101.4841 - softmax_1_loss: 0.0072 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0248 - softmax_1_acc_4: 0.1984 - softmax_1_acc_5: 0.1944 - softmax_1_acc_6: 0.0496 - softmax_1_acc_7: 0.5764 - softmax_1_acc_8: 0.0437 - softmax_1_acc_9: 0.1032 - softmax_1_acc_10: 0.0962 - softmax_1_acc_11: 0.2203 - softmax_1_acc_12: 0.3264 - softmax_1_acc_13: 0.2609 - softmax_1_acc_14: 0.2460 - softmax_1_acc_15: 0.7510 - softmax_1_acc_16: 0.7470 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7391 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8026 - softmax_1_acc_22: 0.8046 - softmax_1_acc_23: 0.8224 - softmax_1_acc_24: 0.8205 - softmax_1_acc_25: 0.9435 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 21s 341ms/step - loss: 100.9610 - softmax_1_loss: 0.0073 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0208 - softmax_1_acc_4: 0.1964 - softmax_1_acc_5: 0.1954 - softmax_1_acc_6: 0.0516 - softmax_1_acc_7: 0.5794 - softmax_1_acc_8: 0.0437 - softmax_1_acc_9: 0.1032 - softmax_1_acc_10: 0.0972 - softmax_1_acc_11: 0.2212 - softmax_1_acc_12: 0.3264 - softmax_1_acc_13: 0.2599 - softmax_1_acc_14: 0.2480 - softmax_1_acc_15: 0.7500 - softmax_1_acc_16: 0.7470 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7431 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8036 - softmax_1_acc_22: 0.8066 - softmax_1_acc_23: 0.8224 - softmax_1_acc_24: 0.8215 - softmax_1_acc_25: 0.9425 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 22s 343ms/step - loss: 100.2867 - softmax_1_loss: 0.0079 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0179 - softmax_1_acc_4: 0.1994 - softmax_1_acc_5: 0.2014 - softmax_1_acc_6: 0.0536 - softmax_1_acc_7: 0.5824 - softmax_1_acc_8: 0.0466 - softmax_1_acc_9: 0.1101 - softmax_1_acc_10: 0.0953 - softmax_1_acc_11: 0.2222 - softmax_1_acc_12: 0.3274 - softmax_1_acc_13: 0.2599 - softmax_1_acc_14: 0.2470 - softmax_1_acc_15: 0.7500 - softmax_1_acc_16: 0.7490 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7401 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8036 - softmax_1_acc_22: 0.8095 - softmax_1_acc_23: 0.8244 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9415 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 23s 358ms/step - loss: 99.6712 - softmax_1_loss: 0.0060 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0208 - softmax_1_acc_4: 0.1974 - softmax_1_acc_5: 0.2014 - softmax_1_acc_6: 0.0536 - softmax_1_acc_7: 0.5853 - softmax_1_acc_8: 0.0486 - softmax_1_acc_9: 0.1121 - softmax_1_acc_10: 0.0972 - softmax_1_acc_11: 0.2232 - softmax_1_acc_12: 0.3274 - softmax_1_acc_13: 0.2619 - softmax_1_acc_14: 0.2500 - softmax_1_acc_15: 0.7510 - softmax_1_acc_16: 0.7490 - softmax_1_acc_17: 0.8502 - softmax_1_acc_18: 0.7411 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8036 - softmax_1_acc_22: 0.8095 - softmax_1_acc_23: 0.8264 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 22s 352ms/step - loss: 99.0765 - softmax_1_loss: 0.0047 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0288 - softmax_1_acc_4: 0.2004 - softmax_1_acc_5: 0.1994 - softmax_1_acc_6: 0.0566 - softmax_1_acc_7: 0.5913 - softmax_1_acc_8: 0.0466 - softmax_1_acc_9: 0.1151 - softmax_1_acc_10: 0.0972 - softmax_1_acc_11: 0.2232 - softmax_1_acc_12: 0.3264 - softmax_1_acc_13: 0.2609 - softmax_1_acc_14: 0.2500 - softmax_1_acc_15: 0.7520 - softmax_1_acc_16: 0.7500 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7431 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8066 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8274 - softmax_1_acc_24: 0.8234 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 22s 344ms/step - loss: 98.5086 - softmax_1_loss: 0.0057 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0298 - softmax_1_acc_4: 0.2034 - softmax_1_acc_5: 0.2014 - softmax_1_acc_6: 0.0585 - softmax_1_acc_7: 0.5962 - softmax_1_acc_8: 0.0486 - softmax_1_acc_9: 0.1151 - softmax_1_acc_10: 0.1002 - softmax_1_acc_11: 0.2242 - softmax_1_acc_12: 0.3264 - softmax_1_acc_13: 0.2619 - softmax_1_acc_14: 0.2510 - softmax_1_acc_15: 0.7520 - softmax_1_acc_16: 0.7500 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7421 - softmax_1_acc_19: 0.8075 - softmax_1_acc_20: 0.7768 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8284 - softmax_1_acc_24: 0.8215 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 23s 372ms/step - loss: 97.9192 - softmax_1_loss: 0.0038 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0347 - softmax_1_acc_4: 0.2054 - softmax_1_acc_5: 0.2024 - softmax_1_acc_6: 0.0605 - softmax_1_acc_7: 0.5952 - softmax_1_acc_8: 0.0526 - softmax_1_acc_9: 0.1161 - softmax_1_acc_10: 0.1012 - softmax_1_acc_11: 0.2262 - softmax_1_acc_12: 0.3274 - softmax_1_acc_13: 0.2629 - softmax_1_acc_14: 0.2580 - softmax_1_acc_15: 0.7530 - softmax_1_acc_16: 0.7500 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7451 - softmax_1_acc_19: 0.8065 - softmax_1_acc_20: 0.7798 - softmax_1_acc_21: 0.8076 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8274 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 22s 357ms/step - loss: 97.3607 - softmax_1_loss: 0.0039 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0387 - softmax_1_acc_4: 0.2034 - softmax_1_acc_5: 0.2053 - softmax_1_acc_6: 0.0615 - softmax_1_acc_7: 0.5943 - softmax_1_acc_8: 0.0516 - softmax_1_acc_9: 0.1201 - softmax_1_acc_10: 0.1012 - softmax_1_acc_11: 0.2252 - softmax_1_acc_12: 0.3284 - softmax_1_acc_13: 0.2659 - softmax_1_acc_14: 0.2599 - softmax_1_acc_15: 0.7540 - softmax_1_acc_16: 0.7500 - softmax_1_acc_17: 0.8492 - softmax_1_acc_18: 0.7460 - softmax_1_acc_19: 0.8075 - softmax_1_acc_20: 0.7798 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8125 - softmax_1_acc_23: 0.8284 - softmax_1_acc_24: 0.8244 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 23s 364ms/step - loss: 96.7341 - softmax_1_loss: 0.0054 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0426 - softmax_1_acc_4: 0.2044 - softmax_1_acc_5: 0.2034 - softmax_1_acc_6: 0.0635 - softmax_1_acc_7: 0.5992 - softmax_1_acc_8: 0.0585 - softmax_1_acc_9: 0.1181 - softmax_1_acc_10: 0.1012 - softmax_1_acc_11: 0.2312 - softmax_1_acc_12: 0.3284 - softmax_1_acc_13: 0.2649 - softmax_1_acc_14: 0.2550 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8502 - softmax_1_acc_18: 0.7460 - softmax_1_acc_19: 0.8095 - softmax_1_acc_20: 0.7798 - softmax_1_acc_21: 0.8095 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8304 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 96.0518 - softmax_1_loss: 0.0039 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0436 - softmax_1_acc_4: 0.2083 - softmax_1_acc_5: 0.2063 - softmax_1_acc_6: 0.0615 - softmax_1_acc_7: 0.6012 - softmax_1_acc_8: 0.0595 - softmax_1_acc_9: 0.1210 - softmax_1_acc_10: 0.1052 - softmax_1_acc_11: 0.2302 - softmax_1_acc_12: 0.3284 - softmax_1_acc_13: 0.2669 - softmax_1_acc_14: 0.2609 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8512 - softmax_1_acc_18: 0.7451 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7818 - softmax_1_acc_21: 0.8095 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8284 - softmax_1_acc_24: 0.8215 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 95.4368 - softmax_1_loss: 0.0067 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0387 - softmax_1_acc_3: 0.0506 - softmax_1_acc_4: 0.2064 - softmax_1_acc_5: 0.2133 - softmax_1_acc_6: 0.0665 - softmax_1_acc_7: 0.6002 - softmax_1_acc_8: 0.0645 - softmax_1_acc_9: 0.1230 - softmax_1_acc_10: 0.1081 - softmax_1_acc_11: 0.2312 - softmax_1_acc_12: 0.3304 - softmax_1_acc_13: 0.2708 - softmax_1_acc_14: 0.2639 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8512 - softmax_1_acc_18: 0.7441 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7847 - softmax_1_acc_21: 0.8095 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8294 - softmax_1_acc_24: 0.8234 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 23s 358ms/step - loss: 94.8319 - softmax_1_loss: 0.0043 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0397 - softmax_1_acc_3: 0.0486 - softmax_1_acc_4: 0.2133 - softmax_1_acc_5: 0.2153 - softmax_1_acc_6: 0.0724 - softmax_1_acc_7: 0.6022 - softmax_1_acc_8: 0.0675 - softmax_1_acc_9: 0.1240 - softmax_1_acc_10: 0.1101 - softmax_1_acc_11: 0.2331 - softmax_1_acc_12: 0.3314 - softmax_1_acc_13: 0.2728 - softmax_1_acc_14: 0.2629 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8532 - softmax_1_acc_18: 0.7460 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7857 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8095 - softmax_1_acc_23: 0.8304 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 23s 371ms/step - loss: 94.1670 - softmax_1_loss: 0.0029 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0417 - softmax_1_acc_3: 0.0526 - softmax_1_acc_4: 0.2123 - softmax_1_acc_5: 0.2202 - softmax_1_acc_6: 0.0734 - softmax_1_acc_7: 0.6012 - softmax_1_acc_8: 0.0635 - softmax_1_acc_9: 0.1250 - softmax_1_acc_10: 0.1091 - softmax_1_acc_11: 0.2351 - softmax_1_acc_12: 0.3333 - softmax_1_acc_13: 0.2728 - softmax_1_acc_14: 0.2639 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8532 - softmax_1_acc_18: 0.7451 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7867 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8105 - softmax_1_acc_23: 0.8304 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9405 - softmax_1_acc_27: 0.9831 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 22s 352ms/step - loss: 93.5435 - softmax_1_loss: 0.0039 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0436 - softmax_1_acc_3: 0.0536 - softmax_1_acc_4: 0.2133 - softmax_1_acc_5: 0.2153 - softmax_1_acc_6: 0.0843 - softmax_1_acc_7: 0.6062 - softmax_1_acc_8: 0.0704 - softmax_1_acc_9: 0.1290 - softmax_1_acc_10: 0.1151 - softmax_1_acc_11: 0.2421 - softmax_1_acc_12: 0.3333 - softmax_1_acc_13: 0.2778 - softmax_1_acc_14: 0.2709 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8532 - softmax_1_acc_18: 0.7480 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7857 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8294 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 22s 346ms/step - loss: 92.7463 - softmax_1_loss: 0.0035 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0446 - softmax_1_acc_3: 0.0585 - softmax_1_acc_4: 0.2202 - softmax_1_acc_5: 0.2272 - softmax_1_acc_6: 0.0893 - softmax_1_acc_7: 0.6062 - softmax_1_acc_8: 0.0734 - softmax_1_acc_9: 0.1260 - softmax_1_acc_10: 0.1151 - softmax_1_acc_11: 0.2460 - softmax_1_acc_12: 0.3333 - softmax_1_acc_13: 0.2748 - softmax_1_acc_14: 0.2689 - softmax_1_acc_15: 0.7560 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8532 - softmax_1_acc_18: 0.7530 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7867 - softmax_1_acc_21: 0.8095 - softmax_1_acc_22: 0.8115 - softmax_1_acc_23: 0.8304 - softmax_1_acc_24: 0.8224 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 22s 348ms/step - loss: 91.9294 - softmax_1_loss: 0.0029 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0486 - softmax_1_acc_3: 0.0635 - softmax_1_acc_4: 0.2193 - softmax_1_acc_5: 0.2282 - softmax_1_acc_6: 0.0863 - softmax_1_acc_7: 0.6062 - softmax_1_acc_8: 0.0774 - softmax_1_acc_9: 0.1310 - softmax_1_acc_10: 0.1270 - softmax_1_acc_11: 0.2460 - softmax_1_acc_12: 0.3343 - softmax_1_acc_13: 0.2827 - softmax_1_acc_14: 0.2768 - softmax_1_acc_15: 0.7550 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8542 - softmax_1_acc_18: 0.7510 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7877 - softmax_1_acc_21: 0.8095 - softmax_1_acc_22: 0.8125 - softmax_1_acc_23: 0.8294 - softmax_1_acc_24: 0.8244 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9425 - softmax_1_acc_27: 0.9831 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 22s 343ms/step - loss: 91.1872 - softmax_1_loss: 0.0042 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0516 - softmax_1_acc_3: 0.0675 - softmax_1_acc_4: 0.2262 - softmax_1_acc_5: 0.2361 - softmax_1_acc_6: 0.0913 - softmax_1_acc_7: 0.6042 - softmax_1_acc_8: 0.0824 - softmax_1_acc_9: 0.1330 - softmax_1_acc_10: 0.1220 - softmax_1_acc_11: 0.2520 - softmax_1_acc_12: 0.3324 - softmax_1_acc_13: 0.2797 - softmax_1_acc_14: 0.2808 - softmax_1_acc_15: 0.7560 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8542 - softmax_1_acc_18: 0.7540 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7857 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8125 - softmax_1_acc_23: 0.8294 - softmax_1_acc_24: 0.8244 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 22s 350ms/step - loss: 90.5183 - softmax_1_loss: 0.0048 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0526 - softmax_1_acc_3: 0.0744 - softmax_1_acc_4: 0.2242 - softmax_1_acc_5: 0.2361 - softmax_1_acc_6: 0.0952 - softmax_1_acc_7: 0.6072 - softmax_1_acc_8: 0.0853 - softmax_1_acc_9: 0.1349 - softmax_1_acc_10: 0.1260 - softmax_1_acc_11: 0.2520 - softmax_1_acc_12: 0.3373 - softmax_1_acc_13: 0.2817 - softmax_1_acc_14: 0.2847 - softmax_1_acc_15: 0.7570 - softmax_1_acc_16: 0.7510 - softmax_1_acc_17: 0.8552 - softmax_1_acc_18: 0.7520 - softmax_1_acc_19: 0.8125 - softmax_1_acc_20: 0.7857 - softmax_1_acc_21: 0.8086 - softmax_1_acc_22: 0.8125 - softmax_1_acc_23: 0.8304 - softmax_1_acc_24: 0.8284 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9425 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 22s 347ms/step - loss: 89.5615 - softmax_1_loss: 0.0052 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0546 - softmax_1_acc_2: 0.0575 - softmax_1_acc_3: 0.0794 - softmax_1_acc_4: 0.2242 - softmax_1_acc_5: 0.2430 - softmax_1_acc_6: 0.0992 - softmax_1_acc_7: 0.6081 - softmax_1_acc_8: 0.0903 - softmax_1_acc_9: 0.1359 - softmax_1_acc_10: 0.1289 - softmax_1_acc_11: 0.2570 - softmax_1_acc_12: 0.3353 - softmax_1_acc_13: 0.2907 - softmax_1_acc_14: 0.2937 - softmax_1_acc_15: 0.7570 - softmax_1_acc_16: 0.7540 - softmax_1_acc_17: 0.8532 - softmax_1_acc_18: 0.7540 - softmax_1_acc_19: 0.8125 - softmax_1_acc_20: 0.7887 - softmax_1_acc_21: 0.8095 - softmax_1_acc_22: 0.8145 - softmax_1_acc_23: 0.8304 - softmax_1_acc_24: 0.8294 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9425 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 22s 350ms/step - loss: 88.5703 - softmax_1_loss: 0.0031 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0585 - softmax_1_acc_2: 0.0595 - softmax_1_acc_3: 0.0843 - softmax_1_acc_4: 0.2321 - softmax_1_acc_5: 0.2450 - softmax_1_acc_6: 0.1042 - softmax_1_acc_7: 0.6072 - softmax_1_acc_8: 0.0913 - softmax_1_acc_9: 0.1399 - softmax_1_acc_10: 0.1339 - softmax_1_acc_11: 0.2550 - softmax_1_acc_12: 0.3433 - softmax_1_acc_13: 0.2917 - softmax_1_acc_14: 0.2937 - softmax_1_acc_15: 0.7580 - softmax_1_acc_16: 0.7520 - softmax_1_acc_17: 0.8552 - softmax_1_acc_18: 0.7540 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7887 - softmax_1_acc_21: 0.8105 - softmax_1_acc_22: 0.8145 - softmax_1_acc_23: 0.8333 - softmax_1_acc_24: 0.8314 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9415 - softmax_1_acc_27: 0.9871 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 23s 359ms/step - loss: 87.5910 - softmax_1_loss: 0.0046 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0575 - softmax_1_acc_2: 0.0595 - softmax_1_acc_3: 0.0942 - softmax_1_acc_4: 0.2341 - softmax_1_acc_5: 0.2430 - softmax_1_acc_6: 0.0992 - softmax_1_acc_7: 0.6121 - softmax_1_acc_8: 0.0943 - softmax_1_acc_9: 0.1409 - softmax_1_acc_10: 0.1329 - softmax_1_acc_11: 0.2550 - softmax_1_acc_12: 0.3462 - softmax_1_acc_13: 0.2966 - softmax_1_acc_14: 0.2976 - softmax_1_acc_15: 0.7580 - softmax_1_acc_16: 0.7520 - softmax_1_acc_17: 0.8552 - softmax_1_acc_18: 0.7550 - softmax_1_acc_19: 0.8115 - softmax_1_acc_20: 0.7897 - softmax_1_acc_21: 0.8115 - softmax_1_acc_22: 0.8145 - softmax_1_acc_23: 0.8324 - softmax_1_acc_24: 0.8334 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9425 - softmax_1_acc_27: 0.9861 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 20s 322ms/step - loss: 86.6314 - softmax_1_loss: 0.0035 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0595 - softmax_1_acc_2: 0.0645 - softmax_1_acc_3: 0.0932 - softmax_1_acc_4: 0.2312 - softmax_1_acc_5: 0.2510 - softmax_1_acc_6: 0.1061 - softmax_1_acc_7: 0.6131 - softmax_1_acc_8: 0.1032 - softmax_1_acc_9: 0.1508 - softmax_1_acc_10: 0.1468 - softmax_1_acc_11: 0.2639 - softmax_1_acc_12: 0.3462 - softmax_1_acc_13: 0.2976 - softmax_1_acc_14: 0.3036 - softmax_1_acc_15: 0.7589 - softmax_1_acc_16: 0.7540 - softmax_1_acc_17: 0.8552 - softmax_1_acc_18: 0.7530 - softmax_1_acc_19: 0.8125 - softmax_1_acc_20: 0.7897 - softmax_1_acc_21: 0.8145 - softmax_1_acc_22: 0.8155 - softmax_1_acc_23: 0.8333 - softmax_1_acc_24: 0.8334 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9435 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 85.6950 - softmax_1_loss: 0.0046 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0595 - softmax_1_acc_2: 0.0714 - softmax_1_acc_3: 0.1051 - softmax_1_acc_4: 0.2361 - softmax_1_acc_5: 0.2549 - softmax_1_acc_6: 0.1171 - softmax_1_acc_7: 0.6101 - softmax_1_acc_8: 0.1022 - softmax_1_acc_9: 0.1488 - softmax_1_acc_10: 0.1428 - softmax_1_acc_11: 0.2679 - softmax_1_acc_12: 0.3472 - softmax_1_acc_13: 0.2996 - softmax_1_acc_14: 0.3125 - softmax_1_acc_15: 0.7560 - softmax_1_acc_16: 0.7550 - softmax_1_acc_17: 0.8562 - softmax_1_acc_18: 0.7540 - softmax_1_acc_19: 0.8135 - softmax_1_acc_20: 0.7907 - softmax_1_acc_21: 0.8125 - softmax_1_acc_22: 0.8135 - softmax_1_acc_23: 0.8343 - softmax_1_acc_24: 0.8373 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9445 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 21s 326ms/step - loss: 84.7291 - softmax_1_loss: 0.0038 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0595 - softmax_1_acc_2: 0.0675 - softmax_1_acc_3: 0.1041 - softmax_1_acc_4: 0.2381 - softmax_1_acc_5: 0.2599 - softmax_1_acc_6: 0.1200 - softmax_1_acc_7: 0.6101 - softmax_1_acc_8: 0.1161 - softmax_1_acc_9: 0.1548 - softmax_1_acc_10: 0.1488 - softmax_1_acc_11: 0.2728 - softmax_1_acc_12: 0.3542 - softmax_1_acc_13: 0.3075 - softmax_1_acc_14: 0.3155 - softmax_1_acc_15: 0.7580 - softmax_1_acc_16: 0.7560 - softmax_1_acc_17: 0.8572 - softmax_1_acc_18: 0.7580 - softmax_1_acc_19: 0.8145 - softmax_1_acc_20: 0.7927 - softmax_1_acc_21: 0.8145 - softmax_1_acc_22: 0.8145 - softmax_1_acc_23: 0.8353 - softmax_1_acc_24: 0.8344 - softmax_1_acc_25: 0.9465 - softmax_1_acc_26: 0.9465 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9851 - softmax_1_acc_29: 1.0000\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 22s 351ms/step - loss: 83.7740 - softmax_1_loss: 0.0027 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0595 - softmax_1_acc_2: 0.0734 - softmax_1_acc_3: 0.1091 - softmax_1_acc_4: 0.2421 - softmax_1_acc_5: 0.2619 - softmax_1_acc_6: 0.1200 - softmax_1_acc_7: 0.6151 - softmax_1_acc_8: 0.1111 - softmax_1_acc_9: 0.1617 - softmax_1_acc_10: 0.1537 - softmax_1_acc_11: 0.2738 - softmax_1_acc_12: 0.3561 - softmax_1_acc_13: 0.3165 - softmax_1_acc_14: 0.3234 - softmax_1_acc_15: 0.7609 - softmax_1_acc_16: 0.7560 - softmax_1_acc_17: 0.8601 - softmax_1_acc_18: 0.7599 - softmax_1_acc_19: 0.8145 - softmax_1_acc_20: 0.7907 - softmax_1_acc_21: 0.8145 - softmax_1_acc_22: 0.8155 - softmax_1_acc_23: 0.8363 - softmax_1_acc_24: 0.8403 - softmax_1_acc_25: 0.9455 - softmax_1_acc_26: 0.9455 - softmax_1_acc_27: 0.9861 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 82.8700 - softmax_1_loss: 0.0049 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0615 - softmax_1_acc_2: 0.0813 - softmax_1_acc_3: 0.1131 - softmax_1_acc_4: 0.2470 - softmax_1_acc_5: 0.2698 - softmax_1_acc_6: 0.1250 - softmax_1_acc_7: 0.6111 - softmax_1_acc_8: 0.1220 - softmax_1_acc_9: 0.1667 - softmax_1_acc_10: 0.1557 - softmax_1_acc_11: 0.2718 - softmax_1_acc_12: 0.3631 - softmax_1_acc_13: 0.3244 - softmax_1_acc_14: 0.3284 - softmax_1_acc_15: 0.7599 - softmax_1_acc_16: 0.7589 - softmax_1_acc_17: 0.8591 - softmax_1_acc_18: 0.7580 - softmax_1_acc_19: 0.8145 - softmax_1_acc_20: 0.7937 - softmax_1_acc_21: 0.8175 - softmax_1_acc_22: 0.8155 - softmax_1_acc_23: 0.8343 - softmax_1_acc_24: 0.8393 - softmax_1_acc_25: 0.9445 - softmax_1_acc_26: 0.9425 - softmax_1_acc_27: 0.9861 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 22s 350ms/step - loss: 81.7121 - softmax_1_loss: 0.0025 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0625 - softmax_1_acc_2: 0.0843 - softmax_1_acc_3: 0.1240 - softmax_1_acc_4: 0.2520 - softmax_1_acc_5: 0.2748 - softmax_1_acc_6: 0.1260 - softmax_1_acc_7: 0.6171 - softmax_1_acc_8: 0.1300 - softmax_1_acc_9: 0.1756 - softmax_1_acc_10: 0.1597 - softmax_1_acc_11: 0.2818 - softmax_1_acc_12: 0.3641 - softmax_1_acc_13: 0.3145 - softmax_1_acc_14: 0.3294 - softmax_1_acc_15: 0.7629 - softmax_1_acc_16: 0.7609 - softmax_1_acc_17: 0.8591 - softmax_1_acc_18: 0.7629 - softmax_1_acc_19: 0.8145 - softmax_1_acc_20: 0.7907 - softmax_1_acc_21: 0.8185 - softmax_1_acc_22: 0.8165 - softmax_1_acc_23: 0.8373 - softmax_1_acc_24: 0.8344 - softmax_1_acc_25: 0.9455 - softmax_1_acc_26: 0.9445 - softmax_1_acc_27: 0.9831 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 22s 351ms/step - loss: 80.5659 - softmax_1_loss: 0.0043 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0625 - softmax_1_acc_2: 0.0893 - softmax_1_acc_3: 0.1230 - softmax_1_acc_4: 0.2570 - softmax_1_acc_5: 0.2728 - softmax_1_acc_6: 0.1389 - softmax_1_acc_7: 0.6210 - softmax_1_acc_8: 0.1359 - softmax_1_acc_9: 0.1855 - softmax_1_acc_10: 0.1627 - softmax_1_acc_11: 0.2857 - softmax_1_acc_12: 0.3691 - softmax_1_acc_13: 0.3294 - softmax_1_acc_14: 0.3393 - softmax_1_acc_15: 0.7619 - softmax_1_acc_16: 0.7629 - softmax_1_acc_17: 0.8611 - softmax_1_acc_18: 0.7629 - softmax_1_acc_19: 0.8145 - softmax_1_acc_20: 0.7927 - softmax_1_acc_21: 0.8215 - softmax_1_acc_22: 0.8165 - softmax_1_acc_23: 0.8373 - softmax_1_acc_24: 0.8403 - softmax_1_acc_25: 0.9465 - softmax_1_acc_26: 0.9455 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 1.0000\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 26s 415ms/step - loss: 79.4957 - softmax_1_loss: 0.0073 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0625 - softmax_1_acc_2: 0.0932 - softmax_1_acc_3: 0.1280 - softmax_1_acc_4: 0.2679 - softmax_1_acc_5: 0.2857 - softmax_1_acc_6: 0.1508 - softmax_1_acc_7: 0.6220 - softmax_1_acc_8: 0.1369 - softmax_1_acc_9: 0.1796 - softmax_1_acc_10: 0.1736 - softmax_1_acc_11: 0.2907 - softmax_1_acc_12: 0.3740 - softmax_1_acc_13: 0.3333 - softmax_1_acc_14: 0.3353 - softmax_1_acc_15: 0.7639 - softmax_1_acc_16: 0.7639 - softmax_1_acc_17: 0.8651 - softmax_1_acc_18: 0.7669 - softmax_1_acc_19: 0.8155 - softmax_1_acc_20: 0.7927 - softmax_1_acc_21: 0.8205 - softmax_1_acc_22: 0.8155 - softmax_1_acc_23: 0.8393 - softmax_1_acc_24: 0.8403 - softmax_1_acc_25: 0.9465 - softmax_1_acc_26: 0.9465 - softmax_1_acc_27: 0.9871 - softmax_1_acc_28: 0.9851 - softmax_1_acc_29: 0.9990\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 23s 362ms/step - loss: 78.3626 - softmax_1_loss: 0.0107 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0625 - softmax_1_acc_2: 0.0962 - softmax_1_acc_3: 0.1379 - softmax_1_acc_4: 0.2679 - softmax_1_acc_5: 0.2877 - softmax_1_acc_6: 0.1488 - softmax_1_acc_7: 0.6250 - softmax_1_acc_8: 0.1528 - softmax_1_acc_9: 0.2024 - softmax_1_acc_10: 0.1845 - softmax_1_acc_11: 0.2966 - softmax_1_acc_12: 0.3809 - softmax_1_acc_13: 0.3363 - softmax_1_acc_14: 0.3571 - softmax_1_acc_15: 0.7669 - softmax_1_acc_16: 0.7669 - softmax_1_acc_17: 0.8641 - softmax_1_acc_18: 0.7619 - softmax_1_acc_19: 0.8184 - softmax_1_acc_20: 0.7937 - softmax_1_acc_21: 0.8244 - softmax_1_acc_22: 0.8185 - softmax_1_acc_23: 0.8443 - softmax_1_acc_24: 0.8433 - softmax_1_acc_25: 0.9455 - softmax_1_acc_26: 0.9474 - softmax_1_acc_27: 0.9851 - softmax_1_acc_28: 0.9841 - softmax_1_acc_29: 0.9990\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 23s 370ms/step - loss: 77.1969 - softmax_1_loss: 0.0029 - softmax_1_acc: 0.0476 - softmax_1_acc_1: 0.0655 - softmax_1_acc_2: 0.0952 - softmax_1_acc_3: 0.1448 - softmax_1_acc_4: 0.2738 - softmax_1_acc_5: 0.2956 - softmax_1_acc_6: 0.1518 - softmax_1_acc_7: 0.6300 - softmax_1_acc_8: 0.1439 - softmax_1_acc_9: 0.2054 - softmax_1_acc_10: 0.1974 - softmax_1_acc_11: 0.3046 - softmax_1_acc_12: 0.3839 - softmax_1_acc_13: 0.3482 - softmax_1_acc_14: 0.3581 - softmax_1_acc_15: 0.7649 - softmax_1_acc_16: 0.7619 - softmax_1_acc_17: 0.8681 - softmax_1_acc_18: 0.7679 - softmax_1_acc_19: 0.8194 - softmax_1_acc_20: 0.7976 - softmax_1_acc_21: 0.8284 - softmax_1_acc_22: 0.8215 - softmax_1_acc_23: 0.8423 - softmax_1_acc_24: 0.8403 - softmax_1_acc_25: 0.9504 - softmax_1_acc_26: 0.9465 - softmax_1_acc_27: 0.9841 - softmax_1_acc_28: 0.9851 - softmax_1_acc_29: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185e256b00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit_generator(sample_gen, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loss', 228.00017150878907),\n",
       " ('softmax_1_loss', 7.600812244415283),\n",
       " ('softmax_1_loss', 7.600771919250488),\n",
       " ('softmax_1_loss', 7.601133358001709),\n",
       " ('softmax_1_loss', 7.600981288909912),\n",
       " ('softmax_1_loss', 7.600863983154297),\n",
       " ('softmax_1_loss', 7.600769088745118),\n",
       " ('softmax_1_loss', 7.60083878326416),\n",
       " ('softmax_1_loss', 7.600711822509766),\n",
       " ('softmax_1_loss', 7.600988208770752),\n",
       " ('softmax_1_loss', 7.600934204101563),\n",
       " ('softmax_1_loss', 7.601013465881348),\n",
       " ('softmax_1_loss', 7.600668468475342),\n",
       " ('softmax_1_loss', 7.600816707611084),\n",
       " ('softmax_1_loss', 7.600540649414063),\n",
       " ('softmax_1_loss', 7.600611515045166),\n",
       " ('softmax_1_loss', 7.599866081237793),\n",
       " ('softmax_1_loss', 7.60098501586914),\n",
       " ('softmax_1_loss', 7.60002645111084),\n",
       " ('softmax_1_loss', 7.599902725219726),\n",
       " ('softmax_1_loss', 7.59957597732544),\n",
       " ('softmax_1_loss', 7.599418830871582),\n",
       " ('softmax_1_loss', 7.599229839324951),\n",
       " ('softmax_1_loss', 7.599160152435303),\n",
       " ('softmax_1_loss', 7.598903335571289),\n",
       " ('softmax_1_loss', 7.598750774383545),\n",
       " ('softmax_1_loss', 7.598565826416015),\n",
       " ('softmax_1_loss', 7.598557510375977),\n",
       " ('softmax_1_loss', 7.598373558044433),\n",
       " ('softmax_1_loss', 7.598283206939697),\n",
       " ('softmax_1_loss', 7.598116775512695),\n",
       " ('softmax_1_acc', 0.006),\n",
       " ('softmax_1_acc_1', 0.001),\n",
       " ('softmax_1_acc_2', 0.0),\n",
       " ('softmax_1_acc_3', 0.001),\n",
       " ('softmax_1_acc_4', 0.0),\n",
       " ('softmax_1_acc_5', 0.0),\n",
       " ('softmax_1_acc_6', 0.001),\n",
       " ('softmax_1_acc_7', 0.001),\n",
       " ('softmax_1_acc_8', 0.001),\n",
       " ('softmax_1_acc_9', 0.0),\n",
       " ('softmax_1_acc_10', 0.0),\n",
       " ('softmax_1_acc_11', 0.0),\n",
       " ('softmax_1_acc_12', 0.001),\n",
       " ('softmax_1_acc_13', 0.001),\n",
       " ('softmax_1_acc_14', 0.001),\n",
       " ('softmax_1_acc_15', 0.0),\n",
       " ('softmax_1_acc_16', 0.001),\n",
       " ('softmax_1_acc_17', 0.001),\n",
       " ('softmax_1_acc_18', 0.0),\n",
       " ('softmax_1_acc_19', 0.0),\n",
       " ('softmax_1_acc_20', 0.001),\n",
       " ('softmax_1_acc_21', 0.0),\n",
       " ('softmax_1_acc_22', 0.0),\n",
       " ('softmax_1_acc_23', 0.0),\n",
       " ('softmax_1_acc_24', 0.001),\n",
       " ('softmax_1_acc_25', 0.0),\n",
       " ('softmax_1_acc_26', 0.0),\n",
       " ('softmax_1_acc_27', 0.0),\n",
       " ('softmax_1_acc_28', 0.0),\n",
       " ('softmax_1_acc_29', 0.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = train_model.evaluate_generator(sample_gen)\n",
    "len(sample_gen)\n",
    "list(zip(train_model.metrics_names, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.save_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infer_model(n_x, n_a, Tx):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = Input(shape=(Tx, n_x), name='input_X')\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    \n",
    "    x = Lambda(lambda x: x[:, 0, :])(X)\n",
    "    a = a0\n",
    "    c = c0\n",
    "\n",
    "    lstm_cell = LSTM(units=n_a, return_state=True, name='lstm_0')\n",
    "    dense_layer = Dense(units=n_x, activation='softmax', name='softmax_1')\n",
    "    \n",
    "    def one_hot(x):\n",
    "        x = K.argmax(x)\n",
    "        x = tf.one_hot(x, n_x) \n",
    "        return x\n",
    "    \n",
    "    def select_x(x, i):\n",
    "        return tf.cond(\n",
    "            tf.equal(tf.reduce_sum(X[:, i+1, :]), 0),\n",
    "            lambda : x,\n",
    "            lambda : X[:, i+1, :]\n",
    "        )\n",
    "        \n",
    "    def select_output(x, i):\n",
    "        return tf.cond(\n",
    "            tf.less(i + 1, Tx),\n",
    "            lambda : select_x(x, i),\n",
    "            lambda : x\n",
    "        )\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(Tx - 1):              \n",
    "        x = Reshape(target_shape=(1, -1))(x)\n",
    "        a, x, c = lstm_cell(x, initial_state=[a, c])\n",
    "        x = dense_layer(x)\n",
    "        x = Lambda(one_hot)(x)\n",
    "        \n",
    "        x = Lambda(lambda x: select_output(x, i))(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "        \n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model = create_infer_model(vocabs_size, N_A, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model.load_weights('./weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_couplets(begin_text, infer_model):\n",
    "    x = convert_text_to_onehot(begin_text, vocabs_size, max_len, word2index)\n",
    "    a0 = np.zeros((1, N_A))\n",
    "    c0 = np.zeros((1, N_A))\n",
    "    \n",
    "    result = infer_model.predict([x, a0, c0])\n",
    "    result_text = convert_predict_to_text(np.array(result), index2word)\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天天向上，一一一山风梦；春风，万里，万里万春。      \n"
     ]
    }
   ],
   "source": [
    "text = '天天向上'\n",
    "result_text = write_couplets(text, infer_model)\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
